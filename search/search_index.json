{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#the-knowledge-center","title":"The Knowledge Center","text":"Where you will find everything you need to know about constellr's LST data Land surface temperature of Freiburg, Germany - June 2023 About the Knowledge Center <p>At constellr, we\u2019re committed to equipping you with everything you need to harness the power of thermal intelligence. From open-access Land Surface Temperature datasets to technical information and scientific insights, we believe knowledge should be as accessible as the data that drives it. Whether you're monitoring crop stress, modeling climate impacts, or developing new tools for resilience. We\u2019re created this knowledge center to empower our customers and partners to engage with our thermal products. </p> Discover the Knowledge Center <p>In this knowledge center, you can find information about:  </p> <p> </p> map Our Technology <p>How constellr creates high-resolution LST data.</p> satellite_alt Product Portfolio <p>Dive into the technical details of constellr's LST products.</p> lightbulb Product User Guide <p>Provides details on the product delivery for our customers.</p> settings Data access <p>Learn how to request and download constellr's data.</p> search Explorer Lab <p>Learn more about real-life applications of thermal data.</p> science Open Data Programme <p>Download free datasets to explore our products.</p>"},{"location":"API-documentation/","title":"Constellr API Documentation","text":"<p>This guide outlines how to authenticate, place orders, search, and download your data using the constellr API. For a detailed overview of the latest API, including live examples, refer to the interactive Swagger documentation or Redoc documentation.</p>"},{"location":"API-documentation/#initial-preparation","title":"Initial Preparation","text":"<ul> <li> <p>To access the Constellr UI and API, your company\u2019s email domain must be registered with Constellr. Once registered, you can create an account using your company email.</p> </li> <li> <p>Create an Account: You can create your account via Constellr's end-user platform, which can be found at https://app.constellr.com/signup</p> </li> <li> <p>Activate Account: After registering, you must activate your account by confirming your e-mail address.</p> </li> <li> <p>Once activated, you can begin accessing and retrieving data using the API.</p> </li> </ul>"},{"location":"API-documentation/#usage-notes","title":"Usage Notes","text":"<ul> <li>Add the word <code>Bearer</code> before the access token in the <code>Authorization</code> header for all API requests (except <code>/token</code> endpoint):   <pre><code>Authorization: Bearer &lt;access_token&gt;\n</code></pre></li> <li>If your token expires, you will receive a 401 Not Authenticated error. Request a new token and retry.</li> <li>Never store your credentials in plain text in production code.</li> </ul>"},{"location":"API-documentation/#authentication-api","title":"Authentication API","text":"<p>Endpoint: <code>POST /token</code> Description: Generates an access token to call the API endpoints. Endpoints require a token in the <code>Authorization</code> header as <code>Bearer &lt;token&gt;</code>. Tokens are valid for 24 hours.</p> <p>Headers: <pre><code>{\n  Accept=application/json\n  Content-Type=application/x-www-form-urlencoded\n}\n</code></pre></p> <p>Request Body (in url-encoded format): <pre><code>{\n  username=your_username\n  password=your_password\n}\n</code></pre></p> <p>Example: cURL <pre><code>curl --location 'https://api.constellr.com/token' \\\n--header 'Accept: application/json' \\\n--header 'Content-Type: application/x-www-form-urlencoded' \\\n--data-urlencode 'username=your_username' \\\n--data-urlencode 'password=your_password'\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/token\"\nheaders = {\n  \"Accept\": \"application/json\",\n  \"Content-Type\": \"application/x-www-form-urlencoded\",\n}\ndata = {\n    \"username\": \"your_username\",\n    \"password\": \"your_password\",\n}\n\nresp = requests.post(url, headers=headers, data=data)\ntoken = resp.json().get(\"access_token\")\nprint(token)\n</code></pre></p> <p>Success Response (200): <pre><code>{\n  \"access_token\": \"string\"\n}\n</code></pre></p> <p>Error Responses:</p> <ul> <li>401: Invalid credentials, user not confirmed, token expired or password reset required.</li> <li>422: Request body validation error.</li> </ul>"},{"location":"API-documentation/#orders-api","title":"Orders API","text":"<p>The <code>/orders</code> endpoint allows you to create, list, and retrieve orders for your organization. All operations require authentication via a Bearer token.</p> 1. Create Orders in Batch <p>Endpoint: <code>POST /orders/batch</code> Description: Create multiple new orders for your organization in a single request.  Order Validation: All orders are validated upon submission. If any order is invalid, the entire request is rejected with a 400/404 status code and an error message.  Validation rules:</p> <ul> <li><code>LSTprecision / LSTzoom:</code> <ul> <li>AOI bounding box must not exceed <code>15,000m</code> in width or <code>15,000m</code> in height</li> <li>Order period must start at least <code>8</code> days from the order creation date, last a minimum of <code>7</code> days, and a maximum of <code>365</code> days</li> <li>Frequency options: <code>single_image</code>, <code>max_frequency</code>, <code>once_every_two_weeks</code>, <code>monthly</code></li> </ul> </li> <li><code>LSTfusion:</code><ul> <li>No bounding box restrictions</li> <li>No order period restrictions</li> <li>Frequency options: <code>daily</code></li> </ul> </li> </ul> <p>Request Body Example: <pre><code>{\n  \"use_case\": \"Yield Prediction\",\n  \"comment\": \"Urgent order for Q3 analysis\",\n  \"orders\": [\n    {\n      \"area_of_interest_id\": \"1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\",\n      \"start_date\": \"2025-09-27T10:30:08.004000Z\",\n      \"end_date\": \"2025-10-18T10:30:08.004000Z\",\n      \"frequency\": \"single-image\",\n      \"product_name\": \"LSTprecision\",\n      \"comment\": \"Order for field 42\"\n    }\n  ]\n}\n</code></pre></p> <p>Example: cURL <pre><code>curl -X POST \"https://api.constellr.com/orders/batch\" \\\n  -H 'accept: application/json' \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d @order_payload.json\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/orders/batch\"\nheaders = {\n    \"Authorization\": \"Bearer &lt;access_token&gt;\",\n    \"Content-Type\": \"application/json\",\n    \"accept\": \"application/json\"\n}\n\npayload = {\n    \"use_case\": \"Yield Prediction\",\n    \"comment\": \"Urgent order for Q3 analysis\",\n    \"orders\": [\n        {\n            \"area_of_interest_id\": \"1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\",\n            \"start_date\": \"2025-09-27T10:30:08.004000Z\",\n            \"end_date\": \"2025-10-18T10:30:08.004000Z\",\n            \"frequency\": \"single-image\",\n            \"product_name\": \"LSTprecision\",\n            \"comment\": \"Order for field 42\"\n        }\n    ]\n}\n\nresponse = requests.post(url, headers=headers, json=payload)\nprint(response.status_code)\nprint(response.json())\n</code></pre></p> <p>Response (201): <pre><code>[\n  {\n    \"area_of_interest_id\": \"1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\",\n    \"start_date\": \"2025-09-27T10:30:08.004000Z\",\n    \"end_date\": \"2025-10-18T10:30:08.004000Z\",\n    \"frequency\": \"single-image\",\n    \"product_name\": \"LSTprecision\",\n    \"comment\": \"Order for field 42\",\n    \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n    \"created\": \"2025-08-27T11:54:24.206072Z\",\n    \"state\": \"initial_state\"\n  }\n]\n</code></pre></p> <p>Error Responses:</p> <ul> <li>400: Invalid order request body values.</li> <li>401: Invalid authentication token.</li> <li>403: User not authorized to create orders.</li> <li>404: Resource not found (e.g., AOI or product does not exist).</li> <li>422: Request body validation error.</li> </ul> 2. List All Orders <p>Endpoint: <code>GET /orders</code> Description: List all orders for your organization with pagination and sorting.</p> <p>Query Parameters:</p> <ul> <li> <p><code>limit</code> (optional, default: 10): Maximum number of orders to return.</p> </li> <li> <p><code>offset</code> (optional, default: 0): Number of orders to skip.</p> </li> <li> <p><code>sort</code> (optional): Sort orders by the <code>-created</code> field.</p> </li> </ul> <p>Example: cURL <pre><code>curl -G \"https://api.constellr.com/orders\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\" \\\n  --data-urlencode \"limit=10\" \\\n  --data-urlencode \"offset=0\" \\\n  --data-urlencode \"sort=-created\"\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/orders\"\nheaders = {\"Authorization\": \"Bearer &lt;access_token&gt;\"}\nparams = {\n    \"limit\": 10,\n    \"offset\": 0,\n    \"sort\": \"-created\"\n}\n\nresp = requests.get(url, headers=headers, params=params)\nresp.raise_for_status()\ndata = resp.json()\nprint(data[\"count\"], len(data[\"items\"]))\n</code></pre></p> <p>Response (200): <pre><code>{\n  \"count\": 1,\n  \"items\": [\n    {\n      \"area_of_interest_id\": \"1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\",\n      \"start_date\": \"2025-09-27T10:30:08.004000Z\",\n      \"end_date\": \"2025-10-18T10:30:08.004000Z\",\n      \"frequency\": \"single-image\",\n      \"product_name\": \"LSTprecision\",\n      \"comment\": \"Order for field 42\",\n      \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n      \"created\": \"2025-08-27T11:54:24.206072Z\",\n      \"state\": \"initial_state\"\n    }\n  ]\n}\n</code></pre> Error Responses:</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to view orders.</li> <li>422: Query parameter validation error.</li> </ul> 3. Get Order by ID <p>Endpoint: <code>GET /orders/{order_id}</code> Description: Retrieve a specific order by its unique ID.</p> <p>Example: cURL <pre><code>curl -X GET \"https://api.constellr.com/orders/123e4567-e89b-12d3-a456-426614174000\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\"\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/orders/123e4567-e89b-12d3-a456-426614174000\"\nheaders = {\n    \"Authorization\": \"Bearer &lt;access_token&gt;\"\n}\n\nresponse = requests.get(url, headers=headers)\n\nprint(response.status_code)\nprint(response.json())\n</code></pre></p> <p>Response (200): <pre><code>{\n  \"area_of_interest_id\": \"1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\",\n  \"start_date\": \"2025-09-27T10:30:08.004000Z\",\n  \"end_date\": \"2025-10-18T10:30:08.004000Z\",\n  \"frequency\": \"single-image\",\n  \"product_name\": \"LSTprecision\",\n  \"comment\": \"Order for field 42\",\n  \"id\": \"123e4567-e89b-12d3-a456-426614174000\",\n  \"created\": \"2025-08-27T11:54:24.206072Z\",\n  \"state\": \"initial_state\"\n}\n</code></pre> Error Responses:</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to view the order.</li> <li>404: Order not found.</li> <li>422: Request parameter validation error.</li> </ul> 4. Get Available Order Use Cases <p>Endpoint: <code>GET /orders/meta/use-cases</code> Description:  Returns a list of available order use cases supported by the API.  </p> <p>Example: cURL <pre><code>curl -X GET \"https://api.constellr.com/orders/meta/use-cases\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\"\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/orders/meta/use-cases\"\nheaders = {\n    \"Authorization\": \"Bearer &lt;access_token&gt;\"\n}\n\nresponse = requests.get(url, headers=headers)\n\nprint(response.status_code)\n</code></pre></p> <p>Response (200): <pre><code>[\n  \"Unknown\",\n  \"Adoption of regenerative ag\",\n  \"Algae/Bacteria bloom\",\n  \"Cover crop monitoring\",\n  \"Drought Stress\",\n  \"Yield Prediction\"\n]\n</code></pre></p> <p>Error Responses:</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to view use cases.</li> </ul>"},{"location":"API-documentation/#areas-of-interest-api","title":"Areas of Interest API","text":"<p>The <code>/areas-of-interest</code> endpoint allows you to create, list, and retrieve Areas of Interest (AOIs) for your organization. AOIs define geographic regions used in data orders. All operations require authentication via a Bearer token.</p> 1. Create an Area of Interest <p>Endpoint: <code>POST /areas-of-interest</code> Description: Creates a new Area of Interest (AOI) for your organization.</p> <p>Request Body Example <pre><code>{\n  \"name\": \"Test AOI\",\n  \"description\": \"Test area\",\n  \"geometry\": {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n      [\n        [8.68483, 49.885416],\n        [8.684889, 49.876422],\n        [8.670971, 49.876383],\n        [8.67091, 49.885378],\n        [8.68483, 49.885416]\n      ]\n    ]\n  }\n}\n</code></pre></p> <p>Example: cURL <pre><code>curl -X POST \"https://api.constellr.com/areas-of-interest\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Test AOI\",\n    \"description\": \"Test area\",\n    \"geometry\": {\n      \"type\": \"Polygon\",\n      \"coordinates\": [\n        [\n          [8.68483, 49.885416],\n          [8.684889, 49.876422],\n          [8.670971, 49.876383],\n          [8.67091, 49.885378],\n          [8.68483, 49.885416]\n        ]\n      ]\n    }\n  }'\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/areas-of-interest\"\nheaders = {\n    \"Authorization\": \"Bearer &lt;access_token&gt;\",\n    \"Content-Type\": \"application/json\"\n}\npayload = {\n    \"name\": \"Test AOI\",\n    \"description\": \"Test area\",\n    \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n            [\n                [8.68483, 49.885416],\n                [8.684889, 49.876422],\n                [8.670971, 49.876383],\n                [8.67091, 49.885378],\n                [8.68483, 49.885416]\n            ]\n        ]\n    }\n}\n\nresp = requests.post(url, headers=headers, json=payload)\nresp.raise_for_status()\nprint(resp.json())\n</code></pre></p> <p>Success Response (201) <pre><code>{\n  \"name\": \"Test AOI\",\n  \"geometry\": {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n      [\n        [8.68483, 49.885416],\n        [8.684889, 49.876422],\n        [8.670971, 49.876383],\n        [8.67091, 49.885378],\n        [8.68483, 49.885416]\n      ]\n    ]\n  },\n  \"description\": \"Test area\",\n  \"bbox_width\": 1200.1,\n  \"bbox_height\": 1300.1,\n  \"id\": \"f1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\",\n  \"created\": \"2025-07-31T11:05:29.157539\"\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>400: Invalid AOI request body values.</li> <li>401: Invalid authentication token.</li> <li>403: User not authorized to create AOIs.</li> <li>422: Request body validation error.</li> </ul> 2. Get an Area of Interest by ID <p>Endpoint: <code>GET /areas-of-interest/{area_of_interest_id}</code> Description: Retrieves a specific AOI by its unique ID.</p> <p>Example: cURL <pre><code>curl -X GET \"https://api.constellr.com/areas-of-interest/f1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\"\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"name\": \"Test AOI\",\n  \"geometry\": {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n      [\n        [8.68483, 49.885416],\n        [8.684889, 49.876422],\n        [8.670971, 49.876383],\n        [8.67091, 49.885378],\n        [8.68483, 49.885416]\n      ]\n    ]\n  },\n  \"description\": \"Test area\",\n  \"bbox_width\": 1200.1,\n  \"bbox_height\": 1300.1,\n  \"id\": \"f1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\",\n  \"created\": \"2025-07-31T11:05:29.157539\"\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to view the AOI.</li> <li>404: AOI not found.</li> <li>422: Request parameter validation error.</li> </ul> 3. List Areas of Interest <p>Endpoint: <code>GET /areas-of-interest</code> Description: Lists all AOIs for your organization with pagination and sorting.</p> <p>Query Parameters</p> <ul> <li> <p><code>limit</code> (optional, default: 10): Maximum number of items to return.</p> </li> <li> <p><code>offset</code> (optional, default: 0): Zero-based index of the first item to return.</p> </li> <li> <p><code>sort</code> (optional): Property to sort results by the <code>-created</code> field. Use <code>+</code> or <code>-</code> as a prefix for ascending or descending order.</p> </li> </ul> <p>Example: cURL <pre><code>curl -G \"https://api.constellr.com/areas-of-interest\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\" \\\n  --data-urlencode \"limit=10\" \\\n  --data-urlencode \"offset=0\" \\\n  --data-urlencode \"sort=-created\"\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/areas-of-interest\"\nheaders = {\"Authorization\": \"Bearer &lt;access_token&gt;\"}\nparams = {\n    \"limit\": 10,\n    \"offset\": 0,\n    \"sort\": \"-created\"\n}\n\nresp = requests.get(url, headers=headers, params=params)\nresp.raise_for_status()\ndata = resp.json()\n\nprint(f\"Total AOIs: {data['count']}\")\nfor item in data[\"items\"]:\n    print(item[\"id\"], item[\"name\"])\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"count\": 1,\n  \"items\": [\n    {\n      \"name\": \"Test AOI\",\n      \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n          [\n            [-8.558478, 40.317694],\n            [-8.343601, 40.314150],\n            [-8.365829, 40.186899],\n            [-8.545914, 40.188510],\n            [-8.558478, 40.317694]\n          ]\n        ]\n      },\n      \"description\": \"Test area\",\n      \"bbox_width\": 1200.1,\n      \"bbox_height\": 1300.1,\n      \"id\": \"f1c53eaa-9b26-4c3d-8998-bfc8e9ac1770\",\n      \"created\": \"2025-04-03T10:36:40.348842\"\n    }\n  ]\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to view AOIs.</li> <li>422: Query parameter validation error.</li> </ul> 4. Get Geometry Info from AOI <p>Endpoint: <code>POST /areas-of-interest/geometry-info</code> Description: Get geometry information (bounding box width/height, area) for a provided GeoJSON AOI geometry.</p> <p>Request Body Example <pre><code>{\n  \"type\": \"Feature\",\n  \"geometry\": {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n      [\n        [11.053963, 51.690862],\n        [11.976814, 51.690862],\n        [11.976814, 51.059955],\n        [10.944099, 51.073763],\n        [11.053963, 51.690862]\n      ]\n    ]\n  }\n}\n</code></pre></p> <p>Example: cURL <pre><code>curl -X POST \"https://api.constellr.com/areas-of-interest/geometry-info\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"type\": \"Feature\",\n    \"geometry\": {\n      \"type\": \"Polygon\",\n      \"coordinates\": [\n        [\n          [11.053963, 51.690862],\n          [11.976814, 51.690862],\n          [11.976814, 51.059955],\n          [10.944099, 51.073763],\n          [11.053963, 51.690862]\n        ]\n      ]\n    }\n  }'\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/areas-of-interest/geometry-info\"\nheaders = {\n    \"Authorization\": \"Bearer &lt;access_token&gt;\",\n    \"Content-Type\": \"application/json\",\n}\npayload = {\n    \"type\": \"Feature\",\n    \"geometry\": {\n        \"type\": \"Polygon\",\n        \"coordinates\": [\n            [\n                [11.053963, 51.690862],\n                [11.976814, 51.690862],\n                [11.976814, 51.059955],\n                [10.944099, 51.073763],\n                [11.053963, 51.690862],\n            ]\n        ],\n    },\n}\n\nresp = requests.post(url, headers=headers, json=payload)\nresp.raise_for_status()\ndata = resp.json()\n\nprint(f\"bbox_width: {data['bbox_width']}\")\nprint(f\"bbox_height: {data['bbox_height']}\")\nprint(f\"area: {data['area']}\")\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"bbox_width\": 74218.0,\n  \"bbox_height\": 72561.2,\n  \"area\": 4728768008.0\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>400: Invalid AOI geometry in request body.</li> <li>401: Invalid authentication token.</li> <li>403: User not authorized to access this endpoint.</li> <li>422: Request body validation error.</li> </ul>"},{"location":"API-documentation/#products-api","title":"Products API","text":"<p>The <code>/products</code> endpoint provides access to the list of available constellr products. Use it to explore product details before creating data orders. All operations require authentication via a Bearer token.</p> 1. List Available Products <p>Endpoint: <code>GET /products</code> Description: Retrieves a list of available products for your organization.</p> <p>Example: cURL <pre><code>curl -X GET \"https://api.constellr.com/products\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\"\n</code></pre></p> <p>Success Response (200)</p> <pre><code>[\n  {\"name\": \"LSTprecision\"},\n  {\"name\": \"LSTfusion\"}\n]\n</code></pre> <p>Error Responses</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to access this endpoint.</li> </ul>"},{"location":"API-documentation/#stac-api","title":"STAC API","text":"<p>The <code>/stac</code> endpoint provides access to SpatioTemporal Asset Catalog (STAC) API, allowing you to search and retrieve geospatial data in a standardized format. All operations require authentication via a Bearer token. The endpoints comply with the STAC API specification.</p> 1. Get STAC Landing Page <p>Endpoint: <code>GET /stac</code> Description: Fetches landing page data for the STAC Browser.</p> <p>Example: cURL <pre><code>curl -X GET \"https://api.constellr.com/stac\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\"\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"type\": \"Catalog\",\n  \"id\": \"constellr-stacapi\",\n  \"title\": \"Constellr STAC API\",\n  \"description\": \"Constellr STAC API\",\n  \"stac_version\": \"1.0.0\",\n  \"links\": [\n    {\n      \"rel\": \"self\",\n      \"type\": \"application/json\",\n      \"title\": \"This document\",\n      \"href\": \"https://example.com/stac/\"\n    },\n    {\n      \"rel\": \"data\",\n      \"type\": \"application/json\",\n      \"title\": \"Collections available for this Catalog\",\n      \"href\": \"https://example.com/stac/collections\"\n    }\n  ],\n  \"stac_extensions\": []\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to access this endpoint.</li> </ul> 2. Get Conformance Classes <p>Endpoint: <code>GET /stac/conformance</code> Description: Fetches the conformance classes supported by the STAC API.</p> <p>Example: cURL <pre><code>curl -X GET \"https://api.constellr.com/stac/conformance\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\"\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"conformsTo\": [\n    \"http://www.opengis.net/spec/cql2/1.0/conf/basic-cql2\",\n    \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-json\",\n    \"http://www.opengis.net/spec/cql2/1.0/conf/cql2-text\",\n    \"https://api.stacspec.org/v1.0.0/ogcapi-features#sort\"\n  ]\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to access this endpoint.</li> </ul> 3. List Available Collections <p>Endpoint: <code>GET /stac/collections</code> Description: Fetches the available STAC collections for your organization.</p> <p>Query Parameters (optional):</p> <ul> <li> <p><code>limit</code>: Limits the number of results per page.</p> </li> <li> <p><code>offset</code>: Number of items to skip before starting to collect the result set.</p> </li> <li> <p><code>bbox</code>: Only return items intersecting this bounding box.</p> </li> <li> <p><code>datetime</code>: Only return items with a temporal property intersecting this value.</p> </li> <li> <p><code>sortby</code>: Array of property names to sort by, prefixed by <code>+</code> or <code>-</code>.</p> </li> <li> <p><code>filter</code>: CQL filter expression for filtering items.</p> </li> <li> <p><code>filter-lang</code>: The language used for the <code>filter</code> value (e.g., <code>cql2-json</code>).</p> </li> </ul> <p>Example: cURL <pre><code>curl -G \"https://api.constellr.com/stac/collections\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\" \\\n  --data-urlencode \"limit=5\" \\\n  --data-urlencode \"offset=0\" \\\n  --data-urlencode \"bbox=-122.1,5.1,35.4,53.6\"\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/stac/collections\"\nheaders = {\"Authorization\": \"Bearer &lt;access_token&gt;\"}\nparams = {\n    \"limit\": 5,\n    \"offset\": 0,\n    \"bbox\": \"-122.1,5.1,35.4,53.6\"\n}\n\nresp = requests.get(url, headers=headers, params=params)\nresp.raise_for_status()\ndata = resp.json()\n\nfor collection in data[\"collections\"]:\n    print(collection[\"id\"], \"-\", collection[\"title\"])\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"collections\": [\n    {\n      \"id\": \"lstfusion\",\n      \"type\": \"Collection\",\n      \"links\": [\n        {\n          \"rel\": \"items\",\n          \"href\": \"https://example.com/stac/collections/lstfusion/items\"\n        }\n      ],\n      \"title\": \"LSTfusion Level-3 UTM LST Product\",\n      \"extent\": {\n        \"spatial\": {\"bbox\": [[-122.1, 5.1, 35.4, 53.6]]},\n        \"temporal\": {\n          \"interval\": [[\"2015-02-26T17:00:00+00:00\", \"2025-08-18T11:00:00+00:00\"]]\n        }\n      },\n      \"license\": \"other\",\n      \"description\": \"Land Surface Temperature (LST) Fusion product.\",\n      \"stac_version\": \"1.1.0\"\n    }\n  ],\n  \"links\": [\n    {\"rel\": \"root\", \"href\": \"https://example.com/stac/\"}\n  ],\n  \"numberMatched\": 1,\n  \"numberReturned\": 1\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to access this endpoint.</li> <li>422: Query parameter validation error.</li> </ul> 4. Get a Single Collection <p>Endpoint: <code>GET /stac/collections/{collection_id}</code> Description: Fetches a single STAC collection by its ID.</p> <p>Example: cURL <pre><code>curl -X GET \"https://api.constellr.com/stac/collections/lstfusion\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\"\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/stac/collections/lstfusion\"\n\nheaders = {\n    \"Authorization\": \"Bearer &lt;access_token&gt;\"\n}\n\nresponse = requests.get(url, headers=headers)\n\nprint(response.status_code)\nprint(response.json())\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"id\": \"lstfusion\",\n  \"type\": \"Collection\",\n  \"links\": [\n    {\n      \"rel\": \"items\",\n      \"href\": \"https://example.com/stac/collections/lstfusion/items\"\n    },\n    {\n      \"rel\": \"self\",\n      \"href\": \"https://example.com/stac/collections/lstfusion\"\n    }\n  ],\n  \"title\": \"LSTfusion Level-3 UTM LST Product\",\n  \"extent\": {\n    \"spatial\": {\"bbox\": [[-122.1, 5.1, 35.4, 53.6]]},\n    \"temporal\": {\n      \"interval\": [[\"2015-02-26T17:00:00+00:00\", \"2025-08-18T11:00:00+00:00\"]]\n    }\n  },\n  \"license\": \"other\",\n  \"description\": \"Short description.\",\n  \"stac_version\": \"1.1.0\"\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to access this endpoint.</li> <li>404: Collection not found.</li> <li>422: Request parameter validation error.</li> </ul> 5. Get a Single Item by Collection and Item ID <p>Endpoint: <code>GET /stac/collections/{collection_id}/items/{item_id}</code> Description: Fetches a single STAC item(feature) by collection and item ID.</p> <p>Example: cURL <pre><code>curl -X GET \"https://api.constellr.com/stac/collections/lstfusion/items/item_id\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\"\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\ncollection_id = \"lstfusion\"\nitem_id = \"item_id\"\nurl = f\"https://api.constellr.com/stac/collections/{collection_id}/items/{item_id}\"\nheaders = {\"Authorization\": \"Bearer &lt;access_token&gt;\"}\n\nresp = requests.get(url, headers=headers)\nresp.raise_for_status()\ndata = resp.json()\n\nprint(data[\"id\"], \"-\", data[\"collection\"])\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"id\": \"item_id\",\n  \"type\": \"Feature\",\n  \"bbox\": [8.3, 49.6, 9.0, 50.1],\n  \"geometry\": {\n    \"type\": \"Polygon\",\n    \"coordinates\": [\n      [\n        [8.3, 50.1],\n        [8.3, 49.6],\n        [9.0, 49.6],\n        [9.0, 50.1],\n        [8.3, 50.1]\n      ]\n    ]\n  },\n  \"links\": [\n    {\n      \"rel\": \"collection\",\n      \"href\": \"https://example.com/stac/collections/lstfusion\"\n    },\n    {\n      \"rel\": \"self\",\n      \"href\": \"https://example.com/stac/collections/lstfusion/items/item_id\"\n    }\n  ],\n  \"assets\": {\n    \"lst\": {\n      \"href\": \"s3://bucket/path/lst.tiff\",\n      \"type\": \"image/tiff\"\n    },\n    \"metadata\": {\n      \"href\": \"s3://bucket/path/metadata.json\",\n      \"type\": \"application/json\"\n    }\n  },\n  \"collection\": \"lstfusion\",\n  \"properties\": {\n    \"gsd\": 30,\n    \"datetime\": \"2025-08-18T11:00:00Z\"\n  },\n  \"stac_version\": \"1.1.0\",\n  \"stac_extensions\": []\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>401: Invalid authentication token.</li> <li>403: User not authorized to access this endpoint.</li> <li>404: Item not found.</li> <li>422: Request parameter validation error.</li> </ul> 6. Search STAC Collections <p>Endpoint: <code>POST /stac/search</code> Description: Performs a search on STAC collections using a request body.</p> <p>Request Body Example <pre><code>{\n  \"collections\": [\"lstfusion\"],\n  \"bbox\": [8.3, 49.6, 9.0, 50.1],\n  \"datetime\": \"2025-08-18T11:00:00Z/..\"\n}\n</code></pre> Example: cURL <pre><code>curl -X POST \"https://api.constellr.com/stac/search\" \\\n  -H \"Authorization: Bearer &lt;access_token&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"collections\": [\"lstfusion\"],\n    \"bbox\": [8.3, 49.6, 9.0, 50.1],\n    \"datetime\": \"2025-08-18T11:00:00Z/..\"\n  }'\n</code></pre></p> <p>Example: Python <pre><code>import requests\n\nurl = \"https://api.constellr.com/stac/search\"\nheaders = {\n    \"Authorization\": \"Bearer &lt;access_token&gt;\",\n    \"Content-Type\": \"application/json\",\n}\npayload = {\n    \"collections\": [\"lstfusion\"],\n    \"bbox\": [8.3, 49.6, 9.0, 50.1],\n    \"datetime\": \"2025-08-18T11:00:00Z/..\",\n}\n\nresp = requests.post(url, headers=headers, json=payload)\nresp.raise_for_status()\ndata = resp.json()\n\nprint(\"numberMatched:\", data.get(\"numberMatched\"))\nprint(\"numberReturned:\", data.get(\"numberReturned\"))\n</code></pre></p> <p>Success Response (200) <pre><code>{\n  \"type\": \"FeatureCollection\",\n  \"links\": [\n    {\"rel\": \"root\", \"href\": \"https://example.com/stac/\"},\n    {\"rel\": \"self\", \"href\": \"https://example.com/stac/search\"}\n  ],\n  \"features\": [],\n  \"numberMatched\": 1,\n  \"numberReturned\": 0\n}\n</code></pre></p> <p>Error Responses</p> <ul> <li>400: Invalid search request body values.</li> <li>401: Invalid authentication token.</li> <li>403: User not authorized to access this endpoint.</li> <li>422: Request body validation error.</li> </ul>"},{"location":"Constellr-product-offer/","title":"Constellr's product offer","text":"<p>Our data portfolio in 2025 consists of three distinct data layers that help you maximize insights from land surface temperature (LST).</p> <p>Benefit from our cutting edge proprietary data layers LSTprecision and LSTzoom for high-frequency and high resolution monitoring of your area of interest. LSTprecision's unprecedented temperature sensitivity allows for reliable absolute temperature analysis at 30m while the 10m spatial resolution of LSTzoom can provide you insights with a 10x improvement in sharpness over today's LST standard. Both products are ideal for understanding thermal footprints of urban environments, infrastructure, and vegetation, allowing to generate new temperature-based insights for geospatial analysis, research projects and business use cases.. Dedicated tasking to analyze your areas of interest is available for both products from mid 2025 onwards, shortly after the launch of constellr's first satellite on the 15.01.2025.</p> <p>LSTfusion complements our data offer in 2025 for large scale monitoring. Thanks to constellr's best-in-class data fusion and data assimilation approach leveraging public and proprietary land surface temperature data, you will benefit from temperature insights with reliable, guaranteed daily frequency, allowing continuous monitoring of larger geographic areas to detect trends and temperature patterns.</p> <ul> <li> <p>LSTfusion</p> <p>Large coverage for regional monitoring</p> <p></p> <ul> <li>30m spatial resolution</li> <li>Fused data sources</li> <li>Large area coverage</li> <li>Reliable data frequency</li> </ul> </li> <li> <p>LSTprecision</p> <p>High accuracy for high-value asset monitoring</p> <p></p> <ul> <li>30m native spatial resolution</li> <li>Proprietary data</li> <li>High temperature sensitivity</li> <li>High frequency</li> </ul> </li> <li> <p>LSTzoom</p> <p>High resolution for zooming in on anomalies</p> <p></p> <ul> <li>10m spatial resolution</li> <li>Enriched proprietary data</li> <li>Visually best resolved</li> <li>High frequency </li> </ul> </li> </ul> Pre-cursor products in 2024-2025 <p>If you want to already  explore the benefits of high-resolution land surface temperature analysis today, we recommend you to take a look at our pre-cursor products and get in touch with us. </p> <ul> <li> <p>LST30</p> <p>Large coverage for regional monitoring</p> <p></p> <ul> <li>30m spatial resolution</li> <li>Proprietary LST retrieval</li> <li>Algorithm enhanced public data</li> <li>Large area coverage </li> </ul> </li> <li> <p>LST15</p> <p>For zooming in on anomalies</p> <p></p> <ul> <li>15m spatial resolution</li> <li>Sharpened data</li> <li>Visually best resolved</li> </ul> </li> </ul>"},{"location":"EL-LST-definition/","title":"Land Surface Temperature (LST) definition and its importance","text":"<p>The temperature of the Earth's land surface represents how hot the ground would feel if touched at a specific location. Such temperature is measured using thermal and optical sensors, such as those used by constellr\u2019s satellites. From a satellite perspective, the \"surface\" could be anything visible from space\u2014snow, grass, rooftops, industrial buildings, or forest canopies. Importantly, LST differs from air temperature, which is typically measured by ground-based weather stations at about 2 meters above the surface and reported by weather forecasts. While LST reflects the actual skin temperature of the Earth\u2019s surface, air temperature represents the temperature of the air above it\u2014meaning the two can differ significantly, such as under clear skies and in urban areas. </p> <p></p> Daytime LST monthly composite map, constellr (leveraging a fusion of public data)  <p>Through consistently delivering high-quality LST data over time, it becomes possible to make more intelligent data-driven decisions for the environment, economy, and societal resilience. Surface temperature data empowers actionable intelligence for the sustainable management of agricultural, infrastructural, and industrial assets, as well as science. </p> <p>Scientists monitor Land surface temperature because it affects and is affected by weather and climate patterns. They track how rising greenhouse gas concentrations influence LST and how this in turn impacts glaciers, ice sheets, permafrost, and vegetation.  </p> <p>For farmers, LST is a valuable complement to spectral vegetation indices. While farmers traditionally rely on indices like NDVI to assess plant health and irrigation needs, LST maps offer additional insights\u2014helping detect crop water stress during summer heatwaves and identifying areas at risk of frost damage in winter. </p> <p>City planners utilize LST data to assess urban heat islands and leverage insights for infrastructure planning.  </p> <p>Security and intelligence analysts leverage thermal data to reveal what isotherwise invisible such as human presence, equipment activity, energy use, and environmental change data on land and sea, from terrain analysis to vessel detection.  </p> <p>Industrial operators use LST data to monitor activities at refineries and power plants, enabling better oversight of critical infrastructure, operational safety, and emissions management. </p> <p>For more examples of how LST data can be applied in practice, see the page Thermal Insights</p> \u2190 Previous Article Next Article \u2192"},{"location":"EL-LST-retrieval-process/","title":"Land Surface Temperature (LST) data retrieval process","text":"<p>As shown below, constellr monitors areas of interests as indicated by their customers. It then receives and processes the data from the HiVE constellation, to make the high/quality LST imagery available on a user platform for its customers. </p> <p></p> LST data retrieval process. <p>The captured signal follows a journey of a series of steps:\u202f </p> <ol> <li>The data reaches constellr\u2019s ground segment then are processed using constellr\u2019s land surface temperature retrieval algorithm.\u202f </li> <li>There are various datasets used to retrieve LST including atmospheric conditions during data acquisition, the land cover type as captured by constellr\u2019s optical sensors, as well as topographical data.\u202f </li> <li>The processed data is further transformed into heatmaps, where each pixel represents a specific temperature. One can visualize temperature distribution across areas by attributing colors to various temperature levels, making it easy to identify patterns like hot spots or cooler zones.\u202f </li> <li>Constellr then makes its data available for customers on through the End User Platform.</li> </ol> \u2190 Previous Article Next Article \u2192"},{"location":"EL-processing-thermal-data/","title":"Processing satellite-derived thermal data","text":"<p>When you snap a photo with a standard phone camera, you can instantly view a clear image. However, this is not the case with a scientifically graded thermal imager, such as HiVE\u2019s. For example, take a look at the raw imagery near Toulouse airport from our HiVE thermal imager (simulated). The airport and the nearby river features are hardly distinguishable until post-processing is applied. Therefore, constellr combines the use of VNIR and TIR data to generate high-quality LST imagery. </p> <p></p> Example of raw HIVE thermal image on the left (simulated) vs processed image on the right. <p>The VNIR sensor\u202fon constellr\u2019s satellites is similar to the Sentinel-2 mission, capturing data in the visible and near-infrared spectrum. VNIR data provides crucial contextual information, helping to interpret thermal data accurately by identifying specific features on the ground, such as rivers, vegetation, and urban areas. This is essential for ensuring that temperature measurements are precisely linked to specific locations on Earth.\u202f </p> <p>On the other hand,\u202fThermal Infrared (TIR)\u202fsensors capture the heat emitted by objects on the Earth's surface. This data is critical for detecting temperature variations and identifying hotspots. Constellr captures long-wave thermal data emitted by objects on the Earth\u2019s surface. As displayed above, raw thermal images can be challenging to interpret without the contextual information provided by VNIR data.\u202f Therefore, VNIR data plays a pivotal role in enhancing the usability of thermal images. Without VNIR support, interpreting thermal data can be challenging, as features that appear similar in temperature might look very different in VNIR imagery. This contrast helps analysts pinpoint the exact location and nature of heat anomalies, providing a more accurate understanding of, for example, urban heat patterns.\u202f </p> <p>For example, comparing a standard RGB image with a VNIR-enhanced image near Toulouse airport shows how VNIR data can highlight differences in vegetation, water bodies, and built-up areas. This differentiation is crucial for accurate thermal analysis, ensuring that hotspots are correctly located and identified.</p> <p></p> Toulouse runway and surroundings as a real color image (left) and false color image that includes NIR (right) \u2190 Previous Article"},{"location":"EL-space-instruments-capture/","title":"What our satellites capture","text":"<p>Constellr\u2019s core technology is based on its spaceborne acquisitions by the High-precision Versatile Ecosphere (HiVE) monitoring constellation of micro satellites, the SkyBees. A SkyBee has onboard sensors that acquire high quality thermal and optical imagery. Thus, each SkyBee is equipped with cutting-edge sensors capable of capturing detailed thermal radiation and radiation from the visible and near-infrared (VNIR) part of the spectrum (see Our Technology page for more information). </p> <p></p> Distribution of the wavelengths within the electromagnetic spectrum and their emission sources. <p>To understand this fully, let's dig a bit deeper into the electromagnetic spectrum, which essentially represents all the different forms \u201clight\u201d can appear in. Light from a physical understanding is a wave, and depending on the wavelength, it carries more or less energy. Short wavelengths are ultraviolet (UV) waves which carry a lot of energy; therefore, they can damage our cells at excessive exposure. They are followed by the \u201cvisible light\u201d, i.e. wavelengths that we perceive in different colors. This is followed by the longer infrared wavelengths. The infrared spectrum is very wide and can be divided into the Near Infrared (NIR), Mid Infrared, and Far Infrared. The NIR is an important component of vegetation analysis, as healthy plants reflect a lot of NIR. In comparison, Mid and Far Infrared radiation can give us a sensation of warmth when they reach our skin and are therefore also termed thermal radiation. Furthermore, every object or material with a temperature above absolute zero (0 Kelvin or -273.15\u00b0C) will emit some thermal radiation in the form of infrared waves. This can be captured day and night with the appropriate sensors. </p> <p>Thus, a SkyBee of the HiVE constellation carries one sensor that detects thermal radiation (Far Infrared) emitted from the Earth\u2019s surface and another detects visible and NIR radiation (VNIR) reflected from the same surface, simultaneously. With the captured information, constellr provides Land Surface Temperature (LST), a crucial parameter for climate studies, agriculture, urban planning, and environmental monitoring.</p> <p>See the figure below and Our Technology page for more detail.</p> <p></p> Description of the thermal and optical sensor on constellr's satellites. \u2190 Previous Article Next Article \u2192"},{"location":"EL-unveiling-hidden-insights/","title":"Unveiling hidden insights with thermal data","text":"<p>Thermal satellite imagery provides a direct window into Earth\u2019s temperature patterns by detecting the heat emitted from the surface, offering insights invisible to conventional optical sensors by providing land surface temperature (LST). Surface temperature is a fundamental driver of ecosystem processes, infrastructure behavior, and climate-related change. By mapping heat distribution and tracking temperature dynamics, thermal data plays a crucial role in understanding ecosystem functioning, monitoring infrastructure performance, and detecting the impacts of climate variability and change. </p> <p>Beyond environmental monitoring, thermal observations support applications in disaster response, border monitoring, vessel monitoring, and situational awareness by revealing thermal anomalies associated with wildfires, energy infrastructure disruptions, or unusual heat signatures in remote areas on land and sea. These capabilities contribute to resilience planning and operational awareness while providing a layer of insight that complements conventional imagery for organizations focused on humanitarian, security, and critical infrastructure protection missions. </p> <p></p> First light from SkyBee 1: Tokyo, Japan 2025, examplifying the difference between optical and thermal imagery. <p>Surface temperature measurements play a vital role in advancing progress toward the United Nations Sustainable Development Goals (SDGs). Adopted in 2015 as part of the 2030 Agenda for Sustainable Development, the SDGs form a global blueprint for peace, prosperity, and environmental stewardship. Temperature monitoring plays a critical role in achieving at least 14 of the 17 goals.</p> <p></p> 14 of 17 SDG Goals\u202fUnited Nations, 2024 shown around an image depicting LST Surface temperature of agricultural fields and cities in the delta of the Nile, Egypt, where blue highlights the fields with lower temperature and red the hotter city. <p>LST reveals processes invisible to optical imager, such as evapotranspiration in crops, surface and urban heat islands, or anomalies in industrial infrastructure. Together, optical and thermal data create a richer, more actionable picture of our planet\u2019s surface dynamics. </p> <p>There are many advantages of thermal data, find below a few of the most important ones:\u202f </p> <ul> <li>Faster insights: Temperature is a physical variable, which is a lot closer to insights in many use cases compared to visual data (and will hence need less computational effort to extract the same insights). While there are many reasons why leaf colour changes, temperature-derived vegetative stress is a direct quantification of the health of a plant, on which one can act. Road temperatures directly link to road erosion and maintenance requirements, the heat radiation from a building is highly related to its material and insulation.</li> <li>Early warning capabilities: Anomalies in temperatures, be it in ways of detecting vegetative stress, the radiative heat of a power plant, or monitoring pollution in rivers, indicate symptoms of early damage, even before it is visible to the eye. A loss of yield, a power outage, or an algae blooming downriver can be better prepared for with an earlier understanding of risk and providing the capabilities of early warnings.   </li> <li>Predictive: By using physical and AI models that fill gaps between thermal data points over time and space, we can project these insights into the future. This effectively enables forward-looking analysis to anticipate upcoming thermal conditions, enabling proactive decision-making for operations, maintenance, and network planning.  </li> </ul> <p>Today, thermal Earth observation (EO) data holds immense strategic value, constellr is a key player delivering high quality, spatial resolution, and precision LST. constellr\u2019s LST is improving global and temporal coverage of thermal data, to deliver new value across cities, farms, and ecosystems worldwide.</p> <p>For more information on the different products offered by constellr, see the Portfolio</p> Next Article \u2192"},{"location":"LST-fusion-metadata/","title":"LSTfusion Metadata","text":"<p>This page describes the metadata file used for L2A products. </p> Key Content Type Description product_typestring\"L3\" product_namestring\"LSTfusion\" linkstringURL with complementary documentation and data access info sourcestring \"constellr\"  acquisition_timestringDate and time of the acquisition, ISO 8601 format at UTC time sourcesstring satellite sensors used, e.g. CLMS, MODIS_AQUA, MODIS_TERRA, VIIRS_NOAA20, VIIRS_NPP  resolutionsnumber arraySpatial resolution for this band resolution_unitstring\"m\" bbox_WGS84number arrayBounding box in Lon/Lat (WGS84), RFC 7946 format bbox_utmnumber arrayBounding box in UTM reference system, RFC 7946 format utm_crsstringEPSG code of the UTM Coordinate Reference System used for the dataset processing_start_timestringISO-8601 string indicating start time of imagery processing processing_end_timestringISO-8601 string indicating end time of imagery processing request_aoiobject \u00a0\u00a0typestringPolygon \u00a0\u00a0coordinatesnumber arrayDefault GeoJSON footprint geometryrequest_start_datetimestringISO-8601 start time of imagery request request_end_datetimestringISO-8601 end time of imagery request <p>   Last update: September, 2025 </p>"},{"location":"LST-fusion-product-deliverables/","title":"LSTfusion Data Bundle","text":"<p>Constellr's product deliverables include several layers, which are outlined below.</p>"},{"location":"LST-fusion-product-deliverables/#data-layers","title":"Data layers","text":"<p>For the LSTfusion product, each data layer is available for a given data and hour, which is indicate in its file name using the ISO 8601 date-time convention. Hence, the date is indicated at UTC time as follows: yyyymmddThhZ.</p> Layers Description File Format metadata_yyyymmddThhZ.json Metadata description json lst_yyyymmddThhZ.tiff LST data Cloud optimized geotiff lst_composite_yyyymmddThhZ.tiff Temperature quicklook Cloud optimized geotiff lst_thumbnail_yyyymmddThhZ.jpg LST Thumbnail jpg lst_std_yyyymmddThhZ.tiff Spatial Standard Deviation Cloud optimized geotiff"},{"location":"LST-fusion-product-deliverables/#naming-convention","title":"Naming Convention","text":"<ul> <li>Naming is performed at the point of download  </li> <li>In the EUP UI, the full name is not shown as the hierarchy is available in the UI structure.<ul> <li>For the example below, we show 'Cloudmask' in the appropriate folder</li> </ul> </li> </ul> <p>Files downloaded from the data store follows the following naming convention:</p> <p>Naming convention</p> <p>[Acquisition time] _ [Product] _ [data order ID]</p> <p>Example 20240512T095854Z _ LSTfusion _ cae562b6-04a2-48cf-a044-eb61064e4c9b</p> <p>   Last update: September, 2025 </p>"},{"location":"LST-fusion/","title":"LSTfusion","text":"What is LSTfusion? <p>LSTfusion is an advanced land surface temperature (LST) fusion product, integrating multiple satellite observations across different resolutions and times into a seamless, high-resolution (30m) and temporally harmonized dataset, offered daily at 11am local solar time.     </p> When should you use LSTfusion? <ul> <li>Get the full picture, every day: Seamless, spatially and temporally consistent temperature data at 30m resolution, delivered daily at 11am local time.   </li> <li>No gaps, no blind spots: Clouds or missing inputs will not stop your analysis. Fusion technology fills gaps to create uninterrupted, reliable datasets.  </li> <li>Benchmark and compare with confidence: track long-term trends across regions, surfaces, or objects with detailed thermal profiles and accumulated temperature curves.   </li> <li>Scale from local to national: Perform regional and national comparisons, then zoom in with HiVE or other high-resolution imagery for detailed asset-level insights.   </li> </ul> <p>Prefer highly accurate temperature benchmarks over time? \u2192 Explore LSTprecision Want to visually detect fine-grained variations locally? \u2192 Explore LSTzoom </p> How is LSTfusion created? <p>LSTfusion is the result of combining dynamic diurnal cycle modelling, spatial upscaling techniques, and data assimilation using Kalman filtering. This powerful integration allows us to generate high-resolution, temporally consistent LST data, even when satellite observations are incomplete or missing. It represents a significant achievement, built on advanced research and deep domain expertise.  </p> <p>LSTfusion uses a combination of the highest quality thermal datasets as input:   </p> <ul> <li>Moderate-resolution sensors: MODIS , VIIRS (Level 2 swath LST product).  </li> <li>High-resolution sensors: Landsat 8/9 LST is derived using constellr\u2019s in-house algorithm, combining dynamic emissivity maps with advanced atmospheric correction to deliver sharper, more accurate, and contextually relevant temperature details.  </li> <li>Geostationary datasets: CLMS (Copernicus L3 LST at 5km based on e.g. SEVIRI, GOES, Himawari).  </li> </ul> <p>The key processing components in LSTfusion include:  </p> <p>Diurnal Temperature Cycle (DTC) Modelling </p> <p>The DTC model simulates temperature changes throughout the day using a curve based on Gaussian and reciprocal functions. It is applied in two modes:  </p> <ul> <li>Low-resolution: using hourly CLMS data  </li> <li>Moderate-resolution: combining MODIS and VIIRS data  </li> </ul> <p>The model provides a complete hourly LST prediction even where direct observations are missing.  </p> <p>Resolution Enhancement (Upsampling) </p> <p>DTC parameters are enhanced to 30\u202fm resolution by leveraging the correlation between vegetation cover and LST. Vegetation cover is determined by the Normalized Difference Vegetation Index (NDVI) at 30m resolution that utilizes red and near infra-red bands to best capture vegetation features. The following steps are followed:  </p> <ul> <li>A local polynomial model is fitted between low-resolution DTC and high-resolution NDVI. </li> <li>This relationship is used to infer high-resolution DTC fields. </li> <li>Results are fused spatially to preserve continuity and accuracy. </li> </ul> <p>Data Assimilation </p> <p>Finally, we integrate all data sources using a Kalman filter-based assimilation system that blends model predictions with high-res observations from the Landsat data, i.e. of the highest resolution:  </p> <ul> <li>Tracks LST and its rate of change per pixel.  </li> <li>Adjusts uncertainty dynamically based on observation quality and availability.  </li> <li>Produces robust, spatially coherent thermal maps.  </li> </ul> <p> The processing steps from raw data acquisition by Skybee satellites to LSTfusion L3 product.</p> What are the specifications of LSTfusion? Parameter Value Spatial Resolution TIR: 30m Temporal Resolution Daily Output Time 11:00 am local solar time Coverage Area Configurable AOI Output Format GeoTIFF + Metadata geojson <p>For more see the Technical Specifications page.</p> How accurate is LSTfusion? <p>LSTfusion delivers real, physically meaningful temperature values\u2014not just relative digital numbers. Each data point represents an actual estimate of land surface temperature, expressed in degrees Kelvin, and ready for direct use in scientific analysis, modeling, and decision-making.  </p> <p>We target an accuracy better than 5\u00b0K, and under clear-sky conditions, performance is often even better. While certain factors such as persistent cloud cover, snow, or complex topography can affect precision, we have built in safeguards. Each LSTfusion image provided to you also is accompanied by a quality layer that lets you assess confidence in the data at every pixel.  </p> <p> Scatter plot comparing LSTfusion output with Russell Ranch ground observations. </p> <p>We are also actively validating the product against ground-based measurements and satellite references to ensure you can rely on it not just for visualization, but for real, quantitative insight. </p> What to look forward to in future developments? <p>We have lots of plans to make LSTfusion even more powerful  </p> <ul> <li>to become an hourly dataset to help you follow everything you need throughout the day  </li> <li>to provide forecasts so you can better plan your activities  </li> <li>to include further thermal datasets from our proprietary data of the HiVE constellation for the highest detail  </li> <li>to include Sentinel-3 data and future missions such TRISHNA, LSTM and posssibly SBG (to remain as the state-of-the-art)  </li> </ul> What is included in the product bundle? <p></p> <p>   Last update: September, 2025 </p>"},{"location":"LST-precision-cal-val-procedure/","title":"Cal/Val approach for LSTprecision","text":"<p> The first-generation SkyBee satellites are equipped with two onboard cameras covering the Visible/Near-Infrared (VNIR) and Thermal Infrared (TIR) spectral ranges. Measurements are acquired in ten VNIR bands\u2014comparable to those of Sentinel-2\u2014and four TIR bands between 8 and 12\u202f\u00b5m, similar to those planned for the upcoming LSTM and TRISHNA missions. The detectors produce non-interpretable Digital Numbers (DNs), which are converted into accurate, georeferenced radiance measurements through a dedicated calibration and validation (Cal/Val) framework, enabling the retrieval of reliable land surface temperature and surface reflectance  products. </p> <p>This Cal/Val framework is designed to characterize the detector response to incoming signals and correct for undesired effects. Key aspects include:  </p> <ul> <li>Absolute radiometric response, dynamic range, non-uniformity, noise levels, and temporal stability; </li> <li>Detection of damaged pixels; </li> <li>False signals (e.g., stray light or instrument self-emission in TIR); </li> <li>Geometric parameters such as optical alignment, distortion, and Modulation Transfer Function (MTF).  </li> </ul> <p>Cal/Val procedures begin pre-launch, with comprehensive laboratory calibrations in controlled environments. For example, these use a variety of calibrated reference instruments, such as blackbodies for thermal calibration and uniform light sources in the VNIR, to assess the detector responses, optical alignment, and radiometric accuracy. </p> <p>Post-launch, instrument performance may evolve due to launch effects or aging. Therefore, regular in-orbit calibration procedures are applied during commissioning and routine operations in order to monitor and, when necessary, update the instrument\u2019s performance. These methodologies span a wide range of techniques. </p> <p>Geometric performance and associated calibration parameters are generally updated by analysing images acquired over highly structured areas\u2014such as agricultural regions with regular patterns (e.g., the Dakotas, USA) \u2014 or over sharp, well-defined features such as coastlines or bridges. These types of scenes serve as reliable references for detecting geometric distortions and verifying spatial accuracy. </p> <p>Statistical analyses are employed to detect dead or bad detector pixels or to correct for possible non-uniformities of the detector. Those are complemented by measurements obtained through specific spacecraft manoeuvres such as 90\u00b0-yaw manoeuvre over homogeneous sites or pointing towards the cold deep space support respectively the characterization of detector non-uniformity and dark signal. </p> <p>Operational radiometric calibration in the VNIR range is performed using a vicarious calibration approach. This consists in aligning HiVE top-of-the atmosphere (TOA) radiances with those simultaneously provided by well-characterized, instrumented ground reference sites (e.g. RadCalNet). In the TIR domain, the radiometric calibration relies on a patented cross-calibration approach. It leverages the highly accurate land surface temperature estimates provided by independent geostationary sensors with a high temporal but low spatial resolution These temperatures are converted to simulated TOA radiances using auxiliary data and radiative transfer modelling. The comparison of the simulated and measured radiances enables the regular update of calibration parameters, ensuring continued accuracy of the thermal measurements.  </p> <p>In addition to the calibration procedures, the end-user LSTprecision products are regularly assessed using a set of well-established validation methods and protocols, such as the CEOS Best Practices Protocols for Global Surface Albedo and Land Surface Temperature Product Validation <sup>1</sup>. These protocols provide a harmonized framework for quantitative accuracy assessment, ensuring traceability and consistency across validation efforts.  </p> <p>In addition to the end-user products \u2014 namely, surface reflectance and land surface temperature, some supporting geophysical variables are also regularly evaluated. Specifically, it also includes the assessment of the geolocation accuracy, the instruments Modulation Transfer Function (MTF), atmospheric information (AOT and TCWV), and cloud mask quality which are produced as a interim products supporting the L2 processing based on VNIR data.  </p> <p>Those validation exercises rely on reference ground-based measurements and independent satellite data coming from different networks or sources as listed in the table below. </p> Ground-based Reference Satellite Others Geolocation -- -- Sentinel-2 GRI MTF -- -- Reference Targets SR Radcalnet / (Hypernets) Sentinel-2 -- LST Copernicus LAW  SURFRAD  KIT stations  JPL stations SEVIRI  GOES  HIMAWARI -- AOT/TCWV Aeronet -- -- Reference data or sites used for assessing the LSTprecision product quality. <p>Surface temperatures measured by SkyBee-1 and SkyBee-2 are being compared to the data points from these reference sites, to ensure that the mean deviation will be close to only 1 degree. Such a high accuracy, although challenging to reach, offers opportunities for a large range of use cases based on the detection of thermal anomalies.</p> Example locations of reference sites. <p>The cloud and cloud masking algorithm uses the VNIR data as an input. Here the similarity to Sentinel-2 data is exploited: The HiVE cloud algorithm was extensively validated on S2 reference data, for example on the data published in the Cloud Mask Intercomparison eXercise (CMIX)<sup>2</sup> and is currently partaking in the follow up CMIX II comparison. Here the absolute labelling acuracy as well as class specific accuracies are evaluated. Furthermore, the cloud mask results are visually inspected for HiVE data and will be compared to selected manually labelled cloud masks.</p> <p></p> <p>   Last update: September, 2025 </p>"},{"location":"LST-precision-cal-val-procedure/#footnotes","title":"Footnotes","text":"<ol> <li> <p>Land Product Validation Subgroup (Working Group On Calibration And Validation Committee On Earth Observation Satellites), \u201cLand Surface Temperature Product Validation Best Practice Protocol,\u201d 2017, doi: 10.5067/DOC/CEOSWGCV/LPV/LST.001.  Land Product Validation Subgroup (Working Group On Calibration And Validation Committee On Earth Observation Satellites), \u201cGlobal Surface Albedo Product Validation Best Practice Protocol,\u201d 2018, doi: 10.5067/DOC/CEOSWGCV/LPV/ALBEDO.001.\u00a0\u21a9</p> </li> <li> <p>Skakun et al., \"Cloud Mask Intercomparison eXercise (CMIX): An evaluation of cloud masking algorithms for Landsat 8 and Sentinel-2\", 2022, doi:\u00a0\u21a9</p> </li> </ol>"},{"location":"LST-precision-metadata/","title":"LSTprecision Metadata","text":"<p>This page describes the metadata file used for L2A products. </p> Key Content Type Description product_idstringThe name of this product platformstringThe name of the spacecraft (e.g. SBA01) product_typestring\"L2\" product_namestring\"LSTprecision\" processing_scenariostring\"NRT\" or \"RPR\" acquisition_idstringLocation and time of acquisition acquisition_datetimestringDate and time of the acquisition, ISO 8601 format at UTC time processing_timestringISO-8601 string indicating start time of imagery processing parent_product_keystring linkstring URL with complementary documentation and data access info sourcestring\"constellr\" use_limitationsstringNA atmospheric_data_sourcestring\"ERA5\" or \"CAMS_forecast\" elevation_data_sourcestringDEM used for geometric/topographic correction (usually \"COPERNICUS GLO30\") aerosol_modelstring\"RURAL\" earth_sun_distancefloatEarth\u2013Sun distance for irradiance correction factors thick_cloud_percentagefloatPercentage of pixels covered by thick clouds thin_cloud_percentagefloatPercentage of pixels covered by thin clouds cloud_shadow_percentagefloatPercentage of pixels affected by cloud shadows scl_masks_bandsobject \u00a0\u00a0cloud_mask_classesdictPossible values of cloud mask: 0 = clear; 1 = thick; 2 = thin; 3 = shadow  \u00a0\u00a0castshadow_mask_classesdictPossible values of cast-shadow mask: 0 = clear; 1 = castshadow \u00a0\u00a0landwater_mask_classesdictPossible values of land/water mask: 0 = land; 1 = water \u00a0\u00a0static_landwater_mask_classesdictPossible values of land/water mask: 0 = land; 1 = water qa_masks_bandsobject \u00a0\u00a0blackfill_mask_classesdictPossible values of blackfill mask: 0 = valid data; 1 = no data  \u00a0\u00a0saturated_mask_classesdictPossible values of saturated mask: 0 = valid data; 1 = saturated  \u00a0\u00a0untested_mask_classesdictPossible values of untested mask: 0 = valid data; 1 = untested  sensorsobject \u00a0\u00a0acquisition_starttimestringISO-8601 start time of imagery acquisition \u00a0\u00a0acquisition_endtimestringISO-8601 end time of imagery acquisition \u00a0\u00a0bboxnumber arrayBounding box in Lon/Lat (WGS84), RFC 7946 format \u00a0\u00a0geometryobject \u00a0\u00a0\u00a0\u00a0typestringPolygon \u00a0\u00a0\u00a0\u00a0coordinatesnumber arrayDefault GeoJSON footprint geometry \u00a0\u00a0\u00a0\u00a0crsstringCoordinate reference system \u00a0\u00a0viewing_anglesobject \u00a0\u00a0\u00a0\u00a0azimuth_meanfloatMean viewing azimuth angle [deg] \u00a0\u00a0\u00a0\u00a0zenith_meanfloatMean viewing zenith angle [deg] \u00a0\u00a0solar_anglesobject \u00a0\u00a0\u00a0\u00a0azimuth_meanfloatMean solar azimuth angle [deg] \u00a0\u00a0\u00a0\u00a0zenith_meanfloatMean solar zenith angle [deg] \u00a0\u00a0surface_altitude_medianfloatMean surface elevation (m) \u00a0\u00a0sensorobject\"VNIR\" or \"TIR\" \u00a0\u00a0sensor_idstring arrayList of sensor identifiers \u00a0\u00a0record_idstring arrayList of record IDs forming the product \u00a0\u00a0bandsdict of objects \u00a0\u00a0\u00a0\u00a0namestringName of band \u00a0\u00a0\u00a0\u00a0eo:common_namestringSTAC-compliant band name \u00a0\u00a0\u00a0\u00a0band_centrefloatWavelength of band centre \u00a0\u00a0\u00a0\u00a0band_widthfloatWidth of the band \u00a0\u00a0\u00a0\u00a0band_wavelength_unitstring\"\u00b5m\" \u00a0\u00a0\u00a0\u00a0resolutionsnumber arraySpatial resolution for this band \u00a0\u00a0\u00a0\u00a0resolution_unitstring\"m\" \u00a0\u00a0\u00a0\u00a0dimensionsinteger arrayRows and columns of the image \u00a0\u00a0\u00a0\u00a0esunobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0valuefloatReference irradiance, uncorrected for Earth\u2013Sun distance \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unitstringW/m\u00b2/\u00b5m \u00a0\u00a0\u00a0\u00a0saturated_percentagefloatPercentage of saturated pixels \u00a0\u00a0\u00a0\u00a0nodata_percentagefloatPercentage of nodata pixels \u00a0\u00a0\u00a0\u00a0nottested_percentagefloatPercentage of unverified quality pixels productsobject \u00a0\u00a0VNIRobject \u00a0\u00a0\u00a0\u00a0sensor_idstring arrayList of sensor identifiers \u00a0\u00a0\u00a0\u00a0TCO3floatTotal ozone column (DU) \u00a0\u00a0\u00a0\u00a0TCO3_unitstring\"Dobson Unit\" \u00a0\u00a0\u00a0\u00a0TCO3_sourcestring\"CAMS_fc\" / \"ERA5\" \u00a0\u00a0\u00a0\u00a0AOTobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_medianfloatMedian AOT value used to retrieve SRs \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_unitstring\"1\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_sourcestringSource (\"constellr_DDV\" or \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0DDV_percentagefloat% of DDV(S) pixels (NA if source is \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_file_idstringFilename of L2A AOT product (NA if \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_typestring\"uint16\"; NA if \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_offsetfloatOffset to compute AOT from readings (AOT = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_scale_factorfloatScale factor to compute AOT from readings (AOT = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_nodataintegerFill value \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_formatstring\"COG\"; NA if \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0topographic_correctionboolTopographic correction applied? \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0adjacency_correctionboolAdjacency correction applied? \u00a0\u00a0\u00a0\u00a0TCWVobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_medianfloatMedian TCWV used to retrieve SRs \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_unitstring\"g/cm\u00b2\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_sourcestringSource (\"constellr\"/\"ERA5\"/\"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_file_idstringFilename (NA if \"ERA5\" or \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_typestring\"uint16\"; NA if \"ERA5\" or \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_offsetfloatOffset to compute TCWV from readings (tcwv = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_scale_factorfloatScale factor for TCWV from readings (tcwv = DN \u00d7 scale_factor + offset); NA if \"ERA5\" or \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_nodataintegerFill value \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_formatstring\"COG\"; NA if \"ERA5\" or \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0topographic_correctionboolTopographic correction applied? \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0adjacency_correctionboolAdjacency correction applied? \u00a0\u00a0\u00a0\u00a0SRobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0topographic_correctionboolTopographic correction applied? \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0adjacency_correctionboolAdjacency correction applied? \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_unitstring\"1\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_typestring\"uint16\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_offsetfloatOffset to compute SR from readings (SR = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_scale_factorfloatScale factor to compute SR from readings (SR = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_nodataintegerFill value \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_formatstring\"COG\" \u00a0\u00a0\u00a0\u00a0Bandsobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0eo:common_namestringSTAC-compliant band name \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0clipped_pixelsintegerNumber of SR pixels clipped to 0 or 1 \u00a0\u00a0TIRobject \u00a0\u00a0\u00a0\u00a0sensor_idstring arrayList of sensor identifiers \u00a0\u00a0\u00a0\u00a0TCO3floatTotal ozone column (DU) \u00a0\u00a0\u00a0\u00a0TCO3_unitstring\"Dobson Unit\" \u00a0\u00a0\u00a0\u00a0TCO3_sourcestring\"CAMS_fc\" / \"ERA5\" \u00a0\u00a0\u00a0\u00a0AOT_medianfloatMedian AOT used to retrieve LSTs \u00a0\u00a0\u00a0\u00a0AOT_unitstring\"1\" \u00a0\u00a0\u00a0\u00a0AOT_sourcestring\"Fixed\"/\"constellr_DDV\"/\"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0AOT_file_idstringFilename of L2A AOT product (NA if \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0TCWV_medianfloatMedian TCWV used to retrieve LSTs \u00a0\u00a0\u00a0\u00a0TCWV_unitstring\"g/cm\u00b2\" \u00a0\u00a0\u00a0\u00a0TCWV_sourcestring\"constellr\"/\"CAMS_fc\"/\"ERA5\" \u00a0\u00a0\u00a0\u00a0TCWV_file_idstringFilename of L2A TCWV product (NA if \"ERA5\" or \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0STobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_typestring\"uint16\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_offsetfloatOffset to compute ST from readings (st = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_scale_factorfloatScale factor to compute ST from readings (st = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_unitstring\"K\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_nodataintegerFill in value \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_formatstring\"COG\" <p></p> <p>   Last update: September, 2025 </p>"},{"location":"LST-precision-product-deliverables/","title":"LSTprecision Data Bundle","text":"<p>Constellr's product deliverables include several layers, which are outlined below.</p>"},{"location":"LST-precision-product-deliverables/#data-layers","title":"Data layers","text":"Layers Description File Format metadata.json Metadata description json vnir01.tiff - vnir10.tiff VNIR Surface Reflection per band at 30m and 60m resolution Cloud optimized geotiff lst.tiff LST data Cloud optimized geotiff rgb_composite.tiff True color (RGB) quicklook Cloud optimized geotiff lst_composite.tiff Temperature quicklook Cloud optimized geotiff rgb_thumbnail.jpg RGB Thumbnail jpg lst_thumbnail.jpg LST Thumbnail jpg scl_mask_XXm.tiff Scene Classification Layer (e.g. vegetation, water) at 30m and 60m resolution Cloud optimized geotiff vnirXX_qa.tiff Quality Assessment Layer for each VNIR band Cloud optimized geotiff tcwv.tiff Total Column Water Vapour Cloud optimized geotiff aot.tiff Aerosol Optical Thickness Cloud optimized geotiff"},{"location":"LST-precision-product-deliverables/#naming-convention","title":"Naming Convention","text":"<p>Files, as described above, will be downloaded via a .zip file from the data store. The .zip file will have the following naming convention:</p> <p>Naming convention</p> <p>[Acquisition time] _ [Product] _ [data order ID]</p> <p>Example 20240512T095854Z _ LSTprecision _ cae562b6-04a2-48cf-a044-eb61064e4c9b</p> <p></p> <p>   Last update: September, 2025 </p>"},{"location":"LST-precision/","title":"LSTprecision","text":"What is LSTprecision? <p>LSTprecision delivers exceptional satellite-based land surface temperature sensitivity and details, enabling accurate absolute temperature measurements. It is designed for precise thermal data, making it ideally suited for urban, vegetation, and industrial analyses with new levels of coverage, detail, and accuracy.  LSTprecision also delivers co-registered accurate surface reflectance measurements across ten visible and near-infrared bands. This enables for example the generation of true-color imagery and the calculation of key vegetation indices providing complementary information for more robust temperature analyses.  </p> When should you use LSTprecision? <ul> <li>Protect high-value assets: Get asset-level insights with accurate thermal data, not just rough indices or proxies. </li> <li>Detect issues before they escalate: Our system acts as an early-warning tool, spotting stress in environments, infrastructure, and materials before damage occurs. </li> <li>Rely on unmatched temperature accuracy: With absolute precision of &lt;2K, you can trust your data to be consistent, comparable, and reliable over time. </li> <li>See what others miss: A sensitivity of 0.03K uncovers subtle thermal shifts, ensuring confident detection of both relative and absolute changes. </li> <li>Track trends with confidence: High-frequency revisits (as often as every 3 days in daylight) deliver rich time-series data, enabling timely identification of anomalies and long-term patterns. </li> </ul> <p>Want even sharper local detail? \u2192 Explore LSTzoom Need broader, cloud-free daily coverage? \u2192 Discover LSTfusion </p> How is LSTprecision created? <p>LSTprecision is derived from the high-resolution measurements acquired by the SkyBee satellite instruments of constellr\u2019s HiVe constellation. Following an advanced calibration and validation (cal/val) procedure, ensuring highly accurate and well georeferenced radiance data, a sequence of processing steps is applied to generate the full LSTprecision product bundle. </p> <ol> <li> <p>Cloud and Scene Classification:  A deep learning algorithm relying on a U-net convolutional neural network (CNN)1  , classifies pixels into four cloud-related classes: clear sky, thick cloud, thin cloud, and cloud shadow. Additional masks are also generated to distinguish land and water and to detect terrain cast-shadows. </p> </li> <li> <p>Atmospheric Correction Inputs:  Two key atmospheric parameters are retrieved from the data: </p> <ul> <li>Aerosol Optical Thickness (AOT) using the Dense Dark Vegetation (DDV) method. </li> <li>Total Column Water Vapor (TCWV) via the Atmospheric Pre-corrected Differential Absorption (APDA) technique.  </li> </ul> <p>We make use of  high quality and well established datasets ERA5 and CAMS_forecast datasets to complement our imagery. Depending on availability, we seamlessly draw from either source, ensuring robust and reliable parameter coverage with consistently high-quality results. </p> </li> <li> <p>Surface Reflectance (SR) Retrieval:  Surface Reflectances are derived from the ten VNIR bands (link to our technology page) using as input the generated masks and atmospheric amounts. The constellr SR algorithm includes corrections for adjacency and terrain using topographic data (Copernicus GLO30 DEM), providing SR with high accuracy for any type of scenes, including vegetation, or buildings and infrastructure suitable for a large range of applications.  </p> </li> <li> <p>Land Surface Temperature (LST) Retrieval:  The VNIR SRs are derived from the satellite footprints and used to estimate an initial (first-guess) emissivity for each of the four thermal bands (link to technology page). Those are used as input of the constellr LST algorithm, relying on the Equivalent Temperature Approach (ETA), to derive the land surface temperature and to optimize the surface emissivity\u2019s. The simultaneous retrieval of LST and emissivity\u2019s enhance the overall LSTprecision product accuracy. </p> </li> </ol> <p> The processing steps from raw data acquisition by Skybee satellites to LSTprecision L2 product.</p> What are the specifications of LSTprecision? Parameter Value Spatial Resolution TIR: 30m, VNIR:10m Temporal Resolution 1.5-3 days Output Time 10:30 or 13:30 local solar time Coverage Area Worldwide tasking, up to 1.000.000 km\u00b2 daily imaging capacity, AOI maximum size: 15x15 km\u00b2 Output Format GeoTIFF + Metadata geojson, ARD-compliant <p>For more see the Technical Specifications page.</p> How accurate is LSTprecision? <p>Thanks to the robust Cal/Val approach combined with state-of-the art algorithm processors, the SkyBee data offer a high level of accuracy from the radiometric and geometric point of views. The SkyBee satellites use two cameras to capture both visible/near-infrared and thermal infrared images of Earth, similar to the capabilities of other leading observation missions. LST and SR are provided with an absolute accuracy better than 2\u00b0K and 5%, respectively, for most clear sky geophysical conditions and with a geolocation accuracy better than XXm. </p> <p>Achieving high accuracy starts well before launch with a proper characterization of the instruments in the lab, and continues in space with a regular verification of the instrumental performances. Engineers monitor and correct for changes over time, detect faulty pixels, and adjust for geometric distortions using well-known landscapes and landmarks. Calibration draws on trusted ground reference sites for visible/near-infrared data and patented methods comparing thermal readings with reliable satellite temperature measurements, guaranteeing data remain precise and reliable throughout the mission.  Accuracy of end-user products is also regularly evaluated against ground-truth measurements at a series of reference sites part of different official networks.  Explore the details of our Cal/Val approach. </p> What to look forward to in future developments? <p>Night time LST imagery In Q4 2025, LSTprecision will also provide nighttime land surface temperature data\u2014offering valuable insights for various urban, defence, and intelligence applications.  With output times at 22:30 and 01:30  local time, the temporal resolution will be improved to less than one day.  </p> <p>Higher revisit frequency  SkyBee-03 is already in the pipeline, with a launch scheduled for mid-2026. It will further reduce revisit times while having the high performance of our first two SkyBee instruments.  </p> <p>Towards a higher spatial resolution The next generation of instruments is already in development, promising enhanced performance, such as higher native spatial resolution, to deliver even greater impact for your applications. </p> What is included in the product bundle? <p></p> <p>   Last update: September, 2025 </p>"},{"location":"LST-zoom-metadata/","title":"LSTzoom Metadata","text":"<p>This page describes the metadata file used for L2A products. </p> Key Content Type Description product_idstringThe name of this product platformstringThe name of the spacecraft (e.g. SBA01) product_typestring\"L2\" product_namestring\"LSTzoom\" processing_scenariostring\"NRT\" or \"RPR\" acquisition_idstringLocation and time of acquisition acquisition_datetimestringDate and time of the acquisition, ISO 8601 format at UTC time processing_timestringISO-8601 string indicating start time of imagery processing parent_product_keystring linkstringURL with complementary documentation and data access info sourcestring\"constellr\" use_limitationsstringNA atmospheric_data_sourcestring\"ERA5\" or \"CAMS_forecast\" elevation_data_sourcestringDEM used for geometric/topographic correction (usually \"COPERNICUS GLO30\") aerosol_modelstring\"RURAL\" earth_sun_distancefloatEarth\u2013Sun distance for irradiance correction factors thick_cloud_percentagefloatPercentage of pixels covered by thick clouds thin_cloud_percentagefloatPercentage of pixels covered by thin clouds cloud_shadow_percentagefloatPercentage of pixels affected by cloud shadows scl_masks_bandsobject \u00a0\u00a0cloud_mask_classesdictPossible values of cloud mask: 0 = clear; 1 = thick; 2 = thin; 3 = shadow  \u00a0\u00a0castshadow_mask_classesdictPossible values of cast-shadow mask: 0 = clear; 1 = castshadow \u00a0\u00a0landwater_mask_classesdictPossible values of land/water mask: 0 = land; 1 = water \u00a0\u00a0static_landwater_mask_classesdictPossible values of land/water mask: 0 = land; 1 = water qa_masks_bandsobject \u00a0\u00a0blackfill_mask_classesdictPossible values of blackfill mask: 0 = valid data; 1 = no data  \u00a0\u00a0saturated_mask_classesdictPossible values of saturated mask: 0 = valid data; 1 = saturated  \u00a0\u00a0untested_mask_classesdictPossible values of untested mask: 0 = valid data; 1 = untested  sensorsobject \u00a0\u00a0acquisition_starttimestringISO-8601 start time of imagery acquisition \u00a0\u00a0acquisition_endtimestringISO-8601 end time of imagery acquisition \u00a0\u00a0bboxnumber arrayBounding box in Lon/Lat (WGS84), RFC 7946 format \u00a0\u00a0geometryobject \u00a0\u00a0\u00a0\u00a0typestringPolygon \u00a0\u00a0\u00a0\u00a0coordinatesnumber arrayDefault GeoJSON footprint geometry \u00a0\u00a0\u00a0\u00a0crsstringCoordinate reference system \u00a0\u00a0viewing_anglesobject \u00a0\u00a0\u00a0\u00a0azimuth_meanfloatMean viewing azimuth angle [deg] \u00a0\u00a0\u00a0\u00a0zenith_meanfloatMean viewing zenith angle [deg] \u00a0\u00a0solar_anglesobject \u00a0\u00a0\u00a0\u00a0azimuth_meanfloatMean solar azimuth angle [deg] \u00a0\u00a0\u00a0\u00a0zenith_meanfloatMean solar zenith angle [deg] \u00a0\u00a0surface_altitude_medianfloatMean surface elevation (m) \u00a0\u00a0sensorobject\"VNIR\" or \"TIR\" \u00a0\u00a0sensor_idstring arrayList of sensor identifiers \u00a0\u00a0record_idstring arrayList of record IDs forming the product \u00a0\u00a0bandsdict of objects \u00a0\u00a0\u00a0\u00a0namestringName of band \u00a0\u00a0\u00a0\u00a0eo:common_namestringSTAC-compliant band name \u00a0\u00a0\u00a0\u00a0band_centrefloatWavelength of band centre \u00a0\u00a0\u00a0\u00a0band_widthfloatWidth of the band \u00a0\u00a0\u00a0\u00a0band_wavelength_unitstring\"\u00b5m\" \u00a0\u00a0\u00a0\u00a0resolutionsnumber arraySpatial resolution for this band \u00a0\u00a0\u00a0\u00a0resolution_unitstring\"m\" \u00a0\u00a0\u00a0\u00a0dimensionsinteger arrayRows and columns of the image \u00a0\u00a0\u00a0\u00a0esunobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0valuefloatReference irradiance, uncorrected for Earth\u2013Sun distance \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0unitstringW/m\u00b2/\u00b5m \u00a0\u00a0\u00a0\u00a0saturated_percentagefloatPercentage of saturated pixels \u00a0\u00a0\u00a0\u00a0nodata_percentagefloatPercentage of nodata pixels \u00a0\u00a0\u00a0\u00a0nottested_percentagefloatPercentage of unverified quality pixels productsobject \u00a0\u00a0VNIRobject \u00a0\u00a0\u00a0\u00a0sensor_idstring arrayList of sensor identifiers \u00a0\u00a0\u00a0\u00a0TCO3floatTotal ozone column (DU) \u00a0\u00a0\u00a0\u00a0TCO3_unitstring\"Dobson Unit\" \u00a0\u00a0\u00a0\u00a0TCO3_sourcestring\"CAMS_fc\" / \"ERA5\" \u00a0\u00a0\u00a0\u00a0AOTobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_medianfloatMedian AOT value used to retrieve SRs \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_unitstring\"1\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_sourcestringSource (\"constellr_DDV\" or \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0DDV_percentagefloat% of DDV(S) pixels (NA if source is \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_file_idstringFilename of L2A AOT product (NA if \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_typestring\"uint16\"; NA if \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_offsetfloatOffset to compute AOT from readings (AOT = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_scale_factorfloatScale factor to compute AOT from readings (AOT = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_nodataintegerFill value \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0AOT_formatstring\"COG\"; NA if \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0topographic_correctionboolTopographic correction applied? \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0adjacency_correctionboolAdjacency correction applied? \u00a0\u00a0\u00a0\u00a0TCWVobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_medianfloatMedian TCWV used to retrieve SRs \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_unitstring\"g/cm\u00b2\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_sourcestringSource (\"constellr\"/\"ERA5\"/\"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_file_idstringFilename (NA if \"ERA5\" or \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_typestring\"uint16\"; NA if \"ERA5\" or \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_offsetfloatOffset to compute TCWV from readings (tcwv = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_scale_factorfloatScale factor for TCWV from readings (tcwv = DN \u00d7 scale_factor + offset); NA if \"ERA5\" or \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_nodataintegerFill value \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0TCWV_formatstring\"COG\"; NA if \"ERA5\" or \"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0topographic_correctionboolTopographic correction applied? \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0adjacency_correctionboolAdjacency correction applied? \u00a0\u00a0\u00a0\u00a0SRobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0topographic_correctionboolTopographic correction applied? \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0adjacency_correctionboolAdjacency correction applied? \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_unitstring\"1\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_typestring\"uint16\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_offsetfloatOffset to compute SR from readings (SR = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_scale_factorfloatScale factor to compute SR from readings (SR = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_nodataintegerFill value \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0SR_formatstring\"COG\" \u00a0\u00a0\u00a0\u00a0Bandsobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0eo:common_namestringSTAC-compliant band name \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0clipped_pixelsintegerNumber of SR pixels clipped to 0 or 1 \u00a0\u00a0TIRobject \u00a0\u00a0\u00a0\u00a0sensor_idstring arrayList of sensor identifiers \u00a0\u00a0\u00a0\u00a0TCO3floatTotal ozone column (DU) \u00a0\u00a0\u00a0\u00a0TCO3_unitstring\"Dobson Unit\" \u00a0\u00a0\u00a0\u00a0TCO3_sourcestring\"CAMS_fc\" / \"ERA5\" \u00a0\u00a0\u00a0\u00a0AOT_medianfloatMedian AOT used to retrieve LSTs \u00a0\u00a0\u00a0\u00a0AOT_unitstring\"1\" \u00a0\u00a0\u00a0\u00a0AOT_sourcestring\"Fixed\"/\"constellr_DDV\"/\"CAMS_fc\" \u00a0\u00a0\u00a0\u00a0AOT_file_idstringFilename of L2A AOT product (NA if \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0TCWV_medianfloatMedian TCWV used to retrieve LSTs \u00a0\u00a0\u00a0\u00a0TCWV_unitstring\"g/cm\u00b2\" \u00a0\u00a0\u00a0\u00a0TCWV_sourcestring\"constellr\"/\"CAMS_fc\"/\"ERA5\" \u00a0\u00a0\u00a0\u00a0TCWV_file_idstringFilename of L2A TCWV product (NA if \"ERA5\" or \"CAMS_fc\") \u00a0\u00a0\u00a0\u00a0STobject \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_typestring\"uint16\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_offsetfloatOffset to compute ST from readings (st = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_scale_factorfloatScale factor to compute ST from readings (st = DN \u00d7 scale_factor + offset) \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_unitstring\"K\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_nodataintegerFill in value \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0ST_formatstring\"COG\" <p></p> <p>   Last update: September, 2025 </p>"},{"location":"LST-zoom-product-deliverables/","title":"LSTzoom Data Bundle","text":"<p>Constellr's product deliverables include several layers, which are outlined below.</p>"},{"location":"LST-zoom-product-deliverables/#data-layers","title":"Data layers","text":"Layers Description File Format metadata.json Metadata description json vnir01.tiff - vnir10.tiff VNIR Surface Reflection per band at 10m, 20m, 30m, and 60m resolution Cloud optimized geotiff lst.tiff LST data Cloud optimized geotiff rgb_composite.tiff True color (RGB) quicklook Cloud optimized geotiff lst_composite.tiff Temperature quicklook Cloud optimized geotiff rgb_thumbnail.jpg RGB Thumbnail jpg lst_thumbnail.jpg LST Thumbnail jpg scl_mask_XXm.tiff Scene Classification Layer (e.g. vegetation, water) at 10m, 20m, 30m, and 60m resolution Cloud optimized geotiff vnirXX_qa.tiff Quality Assessment Layer for each VNIR band Cloud optimized geotiff tcwv.tiff Total Column Water Vapour Cloud optimized geotiff aot.tiff Aerosol Optical Thickness Cloud optimized geotiff"},{"location":"LST-zoom-product-deliverables/#naming-convention","title":"Naming Convention","text":"<p>Files, as described above, will be downloaded via a .zip file from the data store. The .zip file will have the following naming convention:</p> <p>Naming convention</p> <p>[Acquisition time] _ [Product] _ [data order ID]</p> <p>Example 20240512T095854Z _ LSTzoom _ cae562b6-04a2-48cf-a044-eb61064e4c9b</p> <p></p> <p>   Last update: September, 2025 </p>"},{"location":"LST-zoom/","title":"LSTzoom","text":"What is LSTzoom? <p>LSTzoom is optimized for localized analysis where fine spatial detail is critical, such as thermal footprints for defence and intelligence and for infrastructure and industrial hotspots. It is based on our LSTprecision product with an additional sharpening algorithm applied to it to increase the spatial resolution up to 10m.   </p> When should you use LSTzoom? <ul> <li>See more, see clearly: Visually detect even the smallest local variations with high-resolution temperature detail. </li> <li>Effortless understanding: Granular thermal contrasts make interpretation straightforward, turning complex data into clear asset-level insights.  </li> <li>Intelligence at scale: Refined contrast brings hidden patterns to light, unlocking smarter monitoring and decision-making.  </li> <li>Stay ahead of risks: Identify early warning signs of stress across infrastructure, materials, and the environment before problems escalate.  </li> <li>Track change over time: Frequent revisit cycles (as fast as every 3 days in daylight) build a powerful time-series for spotting anomalies and long-term trends with confidence.  </li> </ul> <p>Looking for consistent daily insights across large areas? \u2192 Discover LSTfusion Prefer highly accurate temperature benchmarks over time? \u2192 Explore LSTprecision </p> How is LSTzoom created? <p>LSTzoom is generated by training a Machine Learning model, that learns a mapping between high-resolution VNIR data (10\u202fm) and coarser resolution  temperature of the land surface (30\u202fm). The goal is to upscale the spatial resolution of LST data while preserving accuracy, consistency, and capture the geometric features present in the VNIR data. The key steps involved in training the model and creating the final product are:  </p> <ul> <li>Downsample the VNIR data to 30\u202fm to match the resolution of the LST data.  </li> <li>Select only the most stable, low-noise regions as training samples to ensure sharper, more reliable image enhancement.  </li> <li>Train both local (window-wise) and global models across the scene using the Decision Tree Regressor.  </li> <li>Predict high-resolution LST at 10\u202fm using the trained models and full-resolution VNIR input.  </li> <li>Fuse global and local predictions to generate a robust, high-accuracy estimate.  </li> <li>Apply residual correction to ensure consistency with the original 30\u202fm LST data. </li> </ul> <p>LSTzoom is thus a Level 3 (L3) product that refers to products resulting from the further processing of L2 data or model output based on L2 data and other external datasets, as shown in the figure below. </p> <p> The processing steps from raw data acquisition by Skybee satellites to LSTzoom L3 product</p> What are the specifications of LSTzoom? Parameter Value Spatial Resolution TIR: 10m, VNIR:10m Temporal Resolution 1.5-3 days Output Time 10:30 or 13:30 local solar time Coverage Area Worldwide tasking, up to 1.000.000 km\u00b2 daily imaging capacity Output Format GeoTIFF + Metadata geojson <p>For more see the Technical Specifications page.</p> How accurate is LSTzoom? <p>The methodology used to generate the LSTzoom product was evaluated against high-resolution airborne land surface temperature measurements from the HYTES instrument. The LSTzoom algorithm was applied to a downscaled version of these reference data, and the resulting outputs were compared with the original observations. In challenging urban environments, the estimated accuracy of the method is better than 5 K.  </p> VNIR Quality Limitations What to look forward to in future developments? <p>5m Zoom </p> <p>LSTzoom night </p> <p>Deep Learning architectures </p> What is included in the product bundle? <p></p> <p>   Last update: September, 2025 </p>"},{"location":"Technical-specification/","title":"Technical Specifications","text":""},{"location":"Technical-specification/#overview-product-specifications","title":"Overview Product Specifications <sup>1</sup>","text":"Characteristics LSTprecision LSTzoom LSTfusion Spatial Resolution <sup>2</sup> 30m 10m 30m Swath 17.5km 17.5km Cropped to AOI (max. 110km x 110km) Scene Size 15km x 15km 15km x 15km 110km x 110km Frequency <sup>3</sup> 2025: 1.5 - 3 days  2026: sub-daily 2025: 1.5-3 days  2026: sub-daily 2025: daily  2026: hourly  2027: forecast Coverage worldwide tasking, up to 1.000.000 km\u00b2 daily imaging capacity worldwide tasking, up to 1.000.000 km\u00b2 daily imaging capacity Worldwide Local acquisition time <sup>4</sup> 2025 Q3: 10:30 am &amp; 1:30 pm  2025 Q4: 01:30 am/pm, 10:30h am/pm 2025 Q3: 10:30 am &amp; 1:30 pm  2025 Q4: 01:30 am/pm, 10:30h am/pm 2025: Data delivery for 11:00 am  2026: hourly Type of images 2025 Q3: day imagery  2025 Q4: day and night imagery 2025 Q3: day imagery  2025 Q4: day and night imagery 2025: day imagery  2026: day and night imagery Availability 2025 Q3-ongoing 2025 Q3-ongoing May 2016-ongoing<sup>5</sup> Acquisition Angle up to 30\u00b0 up to 30\u00b0 not applicable Temperature accuracy <sup>6</sup> &lt;1-2K with 0.03K NEDT &lt;3K &lt;5K Latency <sup>7</sup> 2025: &lt;3 days  2026: &lt;12 hrs  2027: &lt;5 h 2025: &lt;3 days  2026: &lt;12 hrs  2027: &lt;5 h not applicable Reactivity 2025: &lt;5 business days  2026: &lt;12 hrs  2027: &lt;1 h 2025: &lt;3 business days  2026: &lt;12 hrs  2027: &lt;1 h not applicable Total request time Sum of the above + revisit time Sum of the above + revisit time 2025: &lt; 3 days  2026: &lt; 24 hrs Calibration and Validation In-situ data validation following CEOS standards.  Patented cross calibration of HiVE with highly accurate calibrated public missions. In-situ data validation following CEOS standards. Patented cross calibration of HiVE with highly accurate calibrated public missions. In-situ data validation following CEOS standards. Patented cross calibration of HiVE with highly accurate calibrated public missions."},{"location":"Technical-specification/#capability-statement","title":"Capability Statement","text":"<p>This document is intented to always provide you the latest version of our capability statement. Download here.  </p>"},{"location":"Technical-specification/#footnotes","title":"Footnotes","text":"<ol> <li> <p>Performances are only warranted for daytime observations of land surfaces (for islands only if larger than 100 km\u00b2) between 50\u00b0S and 55\u00b0N. All numbers are cloud coverage dependent.\u00a0\u21a9</p> </li> <li> <p>Defined as resampled pixel size of Land Surface Temperature (LST) products. For LSTprecision and LSTzoom native nadir looking Ground Sampling Distance (GSD) at 510km altitude is 27.3 m for Thermal Infrared data, while GSD for LSTfusion varies with different input data sources. GSD defined as a pixel projection on ground. For LSTzoom higher resolution VNIR bands are used for sharpening to 10m.\u00a0\u21a9</p> </li> <li> <p>For LSTprecision and LSTzoom frequency relates to the geometric revisit time, defined as the mean number of observation opportunities over a period of 3 months. In 2025 &lt; 4 days is equatorial, &lt; 3 days at \u00b1 40\u00b0+ latitudes and &lt; 2 days between \u00b1 60\u00b0 and \u00b1 80\u00b0 latitude. For LSTfusion frequency defines the regularity with which data output is delivered.\u00a0\u21a9</p> </li> <li> <p>Defined as solar local time, which is time based on the Sun\u2019s actual position in the sky at your location, without considering time zones or daylight saving shifts.\u00a0\u21a9</p> </li> <li> <p>Because LSTfusion combines data from multiple satellites it can deliver Land Surface Temperature maps starting from May 2016 using archived imagery.\u00a0\u21a9</p> </li> <li> <p>Defined as absolute temperature error. Value defined at Mid-Latitude Summer atmosphere, ground temperature of 295K, ground cover with emissivity 0.98. High atmospheric water vapour may lead to local deviations in temperature accuracy. The Noise Equivalent Temperature Difference (NETD) is defined as the minimum resolvable temperature difference.\u00a0\u21a9</p> </li> <li> <p>Defined as the time between image acquisition by a satellite and delivery of LST data corresponding to the acquisition. 2\u03c3 (95%) over 1000 deliveries.\u200b \u200b\u00a0\u21a9</p> </li> </ol>"},{"location":"UI-documentation/","title":"End User Platform - UI Documentation","text":"<p>This page will guide you through the steps to create an account, access it, and browse through the assets list page.</p>"},{"location":"UI-documentation/#login","title":"Login","text":"<p>You can access the End User Platform via the sign in page, using your email and password.  </p> First time user? <p>You will need to create an account via the sign up page.</p> <p>Note To create an account, your organization must be registered with constellr and you must use your company email. In case you need support, please contact: support-csm@constellr.com</p> <p>Step 1 - Create an account</p> <p>You\u2019ll be prompted with a form where you need to provide your e-mail address and password. To create an account, you\u2019ll need to read and accept the terms and conditions. </p> <p>Step 2 - Verify your account</p> <p>To finish creating your account, you will need to enter a verification code which you will receive via e-mail during the sign up process. In the application, you will be prompted to enter the verification code. This code is only valid for 24 hours.  </p> <p>Once the code is entered, the account will be activated, and you can proceed to sign in and access your account.  </p>"},{"location":"UI-documentation/#navigating-the-end-user-platform","title":"Navigating the End User Platform","text":"<p>There are three sections to the platform, which you can access from the sidebar on the left:  </p> <ul> <li>My Data: Access your data and track your orders.  </li> <li>New order: Place a new order. </li> <li>AOI Library: Create and manage your Areas of Interest. </li> </ul> My Data <p>This is the central place for tracking your data orders and downloading your data.  </p> <p>Tracking Orders A table shows an overview of all orders you have placed, including their status, area of interest, product, and monitoring period. At the top of the page, you can search and filter your orders to quickly find the data you need.  </p> <p></p> <p>Each row in the table represents one data order with the following information:  </p> <ul> <li>Data Order ID: The unique identifier for the order.  </li> <li>State: You can use this to track where the order is in it\u2019s lifecycle: <ul> <li>Pending Validation \u2013 waiting for validation by constellr CSMs. </li> <li>In Progress \u2013 the order is active and the system is working to acquire and deliver images to you.  </li> <li>Closing \u2013 this status is triggered when the monitoring period is over. The system is no longer trying to acquire new images. However, we are waiting for any last images taken by the satellite to be downlinked, processed and quality controlled before the order closes.  </li> <li>Closed \u2013 the order is complete and all of your data has been delivered.   </li> </ul> </li> <li>Area of Interest: The AOI being imaged for this order. </li> <li>Frequency: How often data is delivered to you (e.g. Single Image, Weekly, Monthly). This is a target frequency rather than a guaranteed frequency. The real frequency of deliveries may vary based on when acquisitions can take place, cloud coverage, satellite availability etc.  </li> <li>Product: The selected product type for the order (LSTprecision, LSTzoom, LSTfusion). </li> <li>Monitoring Period: The time window for which data is collected.  </li> </ul> <p>Downloading Data You can access your data by clicking on the Data Order ID. Here, you can see every delivery for that order.  </p> <p>Each delivery is named according to when the image was acquired by the satellite. You can expand each delivery to see the files inside of it, and download each delivery by using the download icon at the bottom.  </p> <p></p> New Order <p>To place a new order, you can navigate to the New Order tab. Here, you can simply fill in the order details as prompted. You can submit multiple orders at a time by clicking the  \u2018Add Order\u2019 button before submission. You can also duplicate or remove an order by clicking on the three dots on the top right of each order box.   </p> <p>Upon successful submission, you will receive a confirmation message. Your order will also be visible in the table on the My Data tab.  </p> <p></p> AOI Library <p>This page is under construction and provides limited functionality for the moment.  </p> <p>From the AOI Library tab, you can manage the AOIs that you have defined. You can see the name, creation date and size. You can also download the GeoJSON by clicking the three dots on the upper right of each AOI.  </p> <p>From this page, you can create new AOIs that can be reused when creating orders. You can either draw an AOI or upload polygon coordinates. Each AOI in your account must have a unique name.  </p> <p></p>"},{"location":"demo/","title":"Solutions in Action","text":"<p>Do you want to get started using land surface temperature to derive temperature-based insights? Explore our collection of curated use case stories below. Our use case stories are in-depth examples of what LST data can achieve. Each story outlines a research question and is accompanied with a dataset to answer the question. Get an impression of the datasets we deliver, our data quality, and test data integration. </p>"},{"location":"demo/#lst-for-precision-agriculture","title":"LST for Precision Agriculture","text":"<p>Click here for the full story and datasets: Detecting water stress in crop fields using LST30</p> <p></p>"},{"location":"demo/#lst-for-urban-planning","title":"LST for Urban planning","text":"<p>Click here for the full story and datasets: Mapping the invisible: using spaceborne LST data to uncover building vacancy</p> <p></p>"},{"location":"example-datasets/","title":"Open Data Programme","text":"Explore our comprehensive collection of high-resolution space-based satellite datasets. <p>After downloading the datasets, find more information on the different layers and metadata here:</p> <ul> <li>LSTprecision Data Bundle Description </li> <li>LSTzoom Data Bundle Description </li> </ul> <p></p> Product Use Cases Price <p>You're about to download: </p> Name Company * Email              *               I agree to allow Constellr GmbH. to store and process my personal data.               Read our Privacy Policy.              Cancel DOWNLOAD DATASET \u2192 Thank You! <p></p>"},{"location":"example-datasets/#downloadModalLabel","title":"Download Dataset","text":""},{"location":"explorer-lab/","title":"Explorer Lab","text":"<ul> <li> <p> LST Essentials You want to learn more about how constellr's satellites capture thermal radiation from earth and why that is important?     Then learn more about the basics of LST in our curated LST essentials articles \u2192 </p> </li> <li> <p> Solutions in Action You are interested in analysis-ready examples of what LST data can achieve?      Explore our collection of use case stories \u2192 which are accompanied with an LST-based dataset.  </p> </li> <li> <p> Open Data Programme You want to get started using land surface temperature to derive temperature-based insights by yourself?     Use our Open Data Programme \u2192 to experience our state-of-the-art imagery first-hand and for free.  </p> </li> </ul>"},{"location":"explorer-lab/#lst-essentials","title":"LST Essentials","text":"3 min read Unveiling hidden insights with thermal data <p>Thermal satellite imagery provides a direct window into Earth\u2019s temperature patterns by detecting the heat emitted from the surface.</p> Read article \u2192 2 min read LST definition and its importance <p>The temperature of the Earth's land surface represents how hot the ground would feel if touched at a specific location.</p> Read article \u2192 2 min read What our space instruments capture <p>To create thermal images, constellr's satellites monitor the earth across a wide range of the electromagnetic spectrum.</p> Read article \u2192 2 min read LST data retrieval process <p>constellr processes the data from the HiVE constellation, to make the high/quality LST imagery available on a user platform for its customers.</p> Read article \u2192 1 min read Processing satellite-derived thermal data <p>Processing thermal data is essentially different from processing optical data.</p> Read article \u2192"},{"location":"explorer-lab/#solutions-in-action","title":"Solutions in Action","text":"<p>Do you want to get started using land surface temperature to derive temperature-based insights? Explore our collection of curated use case stories below. Our use case stories are in-depth examples of what LST data can achieve. Each story outlines a research question and is accompanied with a dataset to answer the question. Get an impression of the datasets we deliver, our data quality, and test data integration. </p> 6 min read LST for Precision Agriculture \ud83d\udccd United States <p>Satellites equipped to measure LST can detect water stress, often long before it becomes visible.</p> Read article \u2192 9 min read LST for Urban Planning \ud83d\udccd Sapporo, Japan <p>constellr tested the ability of thermal data to identify vacant housing, confronting Japan's housing crisis.</p> Read article \u2192"},{"location":"lst30/","title":"Lst30","text":"Constellr LST30 <p>Prior to the launch of HiVE\u2019s satellites, constellr has been preparing for HiVE\u2019s data since 2022. constellr developed sapproaches to derive LST from thermal data including LisR, to assess and validate the use of LST data for various use-cases, and finally to understand the impact that HiVE would bring to each solution. Thus, constellr developed its first product, LST30, that consists of homogenized rasters of LST acquired from various thermal public missions along with available proprietary data. LST30 is comprised of harmonized LST data that are retrieved by constellr\u2019s in-house technology. It utilizes proprietary data (LisR), as well as raw thermal data acquired by the Landsat 8 and 9 missions (courtesy of U.S. Geological Survey), Ecostress (courtesy of NASA - JPL), and climatic data (courtesy of the Copernicus Climate Change Service/ECMWF). Yet, the data are delivered as if they were coming from a single satellite constellation with perfect pixel alignment in all images, regardless of the source.    </p> <p>Leveraging thermal data of LST30 has been a success, where the potential of LST has been highlighted for enhancing smart agriculture, monitoring urban heat islands, and optimizing infrastructure resilience. By validating the reliability and applicability of the data, cosntellr has ensured the effective integration of spaceborne LST in diverse, real-world scenarios, driving impact across multiple sectors.  </p> <p>Key Technical Characteristics of LST30: </p> Characteristics LST30 Spatial resolution 30m Spatial coverage Worldwide Scene size 110km x 110km Temporal resolution 8 days Temporal archive 2014 - ongoing Bands LST  Cloud Mask <p>For more details and a comparison with our other products, have a look at our Technical specifications documentation here.  </p> <p>Various layers are provided and follow this compact naming convention:</p> Filename part Meaning YYYYMMDDTHHMMSS Time of sensing LST in isoformat.  Time is based on Universal Time Coordinated (UTC), also known as Greenwhich Mean Time (GMT). aa Indicates what the file contains: <ul><li> LST_AOI.tif: LST raster  pixel value: Kelvin Degree or 'nodata' in case of issues in the data processing from the public providers </li><li>CLOUDS_AOI.tif: Cloud mask raster  pixel values: 0=clear pixel, 1=contamined pixel  cloud mask is made of cloud and shadow pixels</li><li> .json: Metadata json </li></ul>"},{"location":"our-technology/","title":"Our Technology","text":""},{"location":"our-technology/#hive-microsatellites","title":"HiVE microsatellites","text":"<p>Delivering insights never seen before. </p> <p>Our state-of-the-art microsatellite constellation is the High-Precision Versatile Ecosphere (HiVE) monitoring mission. It is a constellation of microsatellites, the SkyBees. These SkyBees are in the 120 kg class, flying in constellation in a similar sun-synchronous orbital plane. The SkyBees orbit Earth at an altitude between 510 km and 590 km with a goal lifetime of 5 years for each satellite. Overpass time is 10:30 am for SkyBee-1 and 1:30 pm is planned for SkyBee-2. Respective night time aquisitions are shifted for 12 hours. </p> <p>HiVE's aim is to deliver Land Surface Temperature data (LST) at a 1-day global temporal resolution, 30 m spatial resolution in the thermal infrared, and better than 2K absolute temperature accuracy. HiVE aims at providing near-real-time temperature mapping across the planet. If it is visible from space, be it snow, crops, rooftops, or forest canopies, we can track its temperature. The comprehensive thermal intelligence we record acts as both a real-time data source and a continuously updated input for calibrating broader data environments. </p> <p></p> Figure 1: HiVE journey, the past and future of constellr's satellites."},{"location":"our-technology/#mission-snapshot","title":"Mission Snapshot","text":"<p>The HiVE mission is owned and operated by constellr and is deployed in orbit via ride-share procured from a third-party launch provider. The ground segment features multiple ground stations, mission planning, tasking, and constellation management functions, as well as User Request I/O and data processing and storage functions. The uniqueness of HiVE is in providing a quantum leap in payload cost efficiency, leveraging our patented virtual calibration technology. Employing thermally stabilized optical systems, cryo-cooled sensors, and a cooperative approach with existing space infrastructure, allows for measurement accuracy comparable to large satellites on a microsatellite platform. </p> <p></p> Figure 2: Planning and processing workflow."},{"location":"our-technology/#payload-overview","title":"Payload Overview","text":"<p>HiVE\u2019s payload is composed of three main elements: a Thermal Infrared (TIR) Instrument, a Visible and Near Infrared (VNIR) Instrument, and a Data Processing Unit (DPU). A Thermal Control System that includes a Heater Control Unit, a Focus Motor Control Unit, and a radiator, is also part of the payload. The total payload mass is 29.17 kg, margins at subsystem and component levels included. </p> <p>The payload is designed as a push-frame imaging system, meaning that multiple spectral bands are consecutively recorded in a push-broom configuration while the field of view of the remote sensing instrument sweeps over the surface of Earth.  </p> <p>The payload is designed such that it can operate either in mapping mode, where continuous stripes are recorded, or in targeting mode, where specific targets are pre-selected and then recorded within the field-of-regard of the satellite. </p>"},{"location":"our-technology/#tir-vnir-instruments","title":"TIR &amp; VNIR instruments","text":"<p>The TIR instrument is HiVE's payload core. </p> <p>The Radiance retrieved by the TIR imager will be transformed to orthorectified Land Surface Temperature using the additional information from the VNIR imager (e.g. geometric information to built the geometric model, Aerosol and Water Vapor information to support the estimation of the atmospheric model and the NDVI to derive a first guess for the emissivity calculations). It achieves a 28.9 m Ground Sampling Distance (GSD) and a 17.5 km swath width at an altitude of 510km. The TIR bands and their central wavelengths, i.e. the wavelength at which the signal is strongest, as well as their respective bandwidth are displayed in Table 1.   </p> Filter Number Central Wavelength [\u00b5m] Bandwidth [nm] 01 8.6 300 02 9.2 300 03 10.6 500 04 11.75 500 Table 1: Spectral bands in the TIR range. <p>At a nominal altitude of 510km, the VNIR camera has a swath width of 21km with a ground sampling distance of 10m. Thus, the camera covers the complete swath of the TIR instrument and can be used for georeferencing. The data binned on board to, dependent on the band, 10m, 20m or 60m. The segmented spectral bandpass filters provide custom spectral channels aligned with those of the Sentinel-2 satellites. The spectral composition of the bands and their spatial resolution how they are delivered in the final orthorectified products is given in Table 2.</p> Filter Number Central Wavelength [\u00b5m] Bandwidth [nm] Targeted GSD [m] 01 443 20 60 02 490 65 10 03 560 35 10 04 665 30 10 05 705 15 20 06 740 15 20 07 783 20 20 08 842 115 10 09 865 20 20 10 945 20 60 Table 2: VNIR band configuration. <p>Thus, together, the VNIR and TIR instruments provide 4 thermal and 10 visible and near infrared bands to enable precise geolocation, atmospheric correction, and cloud detection. For an overview of the sensor specifications, see also Figure 3.</p> <p></p> Figure 3: Overview of the TIR and VNIR sensors."},{"location":"our-technology/#cryocooler-sensor","title":"Cryocooler Sensor","text":"<p>The cryocooled infrared sensors are at the heart of delivering high-quality, high-resolution thermal data from space. Operating at temperatures around 70 Kelvin (-200\u00b0C), these sensors significantly reduce sensor noise, improve signal-to-noise ratios, and ensure minimal thermal drift over time. By cooling the Mercury-Cadmium-Telluride (MCT) detectors to such low temperatures, constellr\u2019s satellites are capable of detecting subtle variations (&lt;0.1K) in thermal energy that are invisible to other commercial thermal EO satellites. </p> <p>Cryocooling technology enables constellr\u2019s HiVE satellites to maintain temperature accuracy within 1\u20132 Kelvin, while offering a 30 m spatial resolution. This level of sensitivity and precision is crucial for applications such as monitoring crop health, managing urban heat islands, and assessing industrial energy efficiency, and civil security. The use of cryocooled sensors ensures that data remains consistent, accurate, and actionable over time.  </p>"},{"location":"our-technology/#data-quality-and-validation","title":"Data Quality and Validation","text":"<p>The HiVE data quality is assessed by defined high standards for all Cal/Val activities. The HiVE Cal/Val activities are supported by ESA within the ESA programs InCubed and Copernicus Contributing Mission (CCM).  </p>"},{"location":"our-technology/#acquisition-scenarios","title":"Acquisition Scenarios","text":"<p>The HiVE constellation is primarily planned as a tasking-based mission with off-nadir pointing capabilities up to \u00b130\u00b0. For 2025, this enables an average revisit time of 1.5 days with the first two satellites, and reaching sub-daily revisit with three satellites (2026+). </p> <p>To learn more about our different products visit our Product Portfolio.</p>"},{"location":"our-technology/#capability-statement","title":"Capability Statement","text":"<p>This document is intented to always provide you the latest version of our capability statement. Download here.</p>"},{"location":"sapporo-use-case/","title":"Sapporo use case","text":"Providing new insights into building occupancy and urban resilience in Japan using themal data <p>Download the graphcial abstract here. </p>"},{"location":"sapporo-use-case/#introduction","title":"Introduction","text":"<p>Japan is confronting a significant vacant housing crisis, with approximately 9 million empty homes nationwide, accounting for 13.6% of all residences. This issue is particularly pronounced in Sapporo, where nearly one in five dwellings is unoccupied. The rise in vacant homes adversely affects property values, increases crime rates, leads to poor sanitation, and contributes to housing market stagnation. Notably, central Sapporo exhibits severe clusters of vacancies, indicating a disequilibrium in the housing market rather than mere urban decline. </p> <p>According to news sources, demographic projections indicate that by 2035, approximately 34.6% of Sapporo's residents will be elderly. This demographic shift is expected to exacerbate the housing vacancy issue, as an aging population may lead to more unoccupied homes, further challenging urban planning and economic stability. </p> Figure 1: A single LST image can capture the whole of Sapporo and provide thermal insights for buildings and industrial objects <p>     To address these challenges, Sapporo has implemented measures for unoccupied houses starting in fiscal year 2015 and formulated the Sapporo Unoccupied House Plan to promote appropriate management and utilization of these properties.  The city formulated the Sapporo Future Creation Plan, which outlines priority measures to counteract population decline and promote economic revitalization. A key strategy involves developing a compact city structure by enhancing public transportation and promoting residential areas around subway stations, aiming to make urban living more attractive and reduce vacancies. Additionally, Sapporo emphasizes community engagement, encouraging resident-led initiatives in urban development to foster vibrant neighborhoods and address the issue of vacant properties.        </p> <p>To address these challenges, Sapporo has implemented measures for unoccupied houses starting in fiscal year 2015 and formulated the Sapporo Unoccupied House Plan to promote appropriate management and utilization of these properties. </p> <p>The city formulated the Sapporo Future Creation Plan, which outlines priority measures to counteract population decline and promote economic revitalization. A key strategy involves developing a compact city structure by enhancing public transportation and promoting residential areas around subway stations, aiming to make urban living more attractive and reduce vacancies. Additionally, Sapporo emphasizes community engagement, encouraging resident-led initiatives in urban development to foster vibrant neighborhoods and address the issue of vacant properties.  </p> <p>By implementing these strategies, Sapporo aims to revitalize its urban environment, effectively manage vacant housing, and ensure sustainable development in the face of demographic changes.  </p> <p>However, current methods of identifying and addressing vacancy are often slow and reactive. constellr tested the ability of thermal data to reveal where vacancies are and why they matter. Thus, we applied our thermal monitoring capabilities to Sapporo. The results offer new insights into how thermal footprints can help cities tackle vacancy challenges and inform smarter urban planning. </p>"},{"location":"sapporo-use-case/#land-surface-temperature-lst-in-the-urban-context","title":"Land Surface Temperature (LST) in the urban context","text":"<p>LST measures the heat emitted from Earth\u2019s surface - whether from a building, a street, or a park. Using constellr\u2019s satellite-based data products, LST is able to capture these data with precision and with large coverage to monitor cities in an integrated manner.  It empowers the way we understand how cities store and release heat, which directly connects to how buildings are used - or left vacant. </p>"},{"location":"sapporo-use-case/#the-sapporo-analysis-ml-classification-using-lst-data","title":"The Sapporo Analysis: ML classification using LST data","text":"<p>Inspired by the 2022 study \u201cVacancy Dwellings Spatial Distribution, The Determinants and Policy Implications in the City of Sapporo, Japan\u201d by Van et al.(2022), constellr conducted an analysis of over 450,000 building footprints in Sapporo. By integrating LST data with population datasets from the Global Human Settlement Layer, our team sought to uncover patterns of building occupancy and vacancy through thermal signatures. </p> <p></p> Figure 2: A machine learning algorithm transforms LST data and complementary information into predictions about building vacancy. <p>A machine learning classification model was trained on LST data and population density information, which created a predictive model capable of classifying dwelling vacancies with an accuracy of 85 percent. In addition, including the morphological settlement zone features collected by Van et al. (2022) improved classification performance by up to 10 percent. This level of accuracy provides a powerful tool for urban planners and policymakers, enabling more informed decision-making about resource allocation, housing policy, and infrastructure management. </p>"},{"location":"sapporo-use-case/#thermal-footprints-as-a-proxy-for-vacancy","title":"Thermal footprints as a proxy for vacancy","text":"<p>The analysis revealed a key feature used to predict housing vacancy using LST data.</p> <p>Sapporo experiences cold winters, with December-January-February being the coldest months. Temperatures commonly fall below 0\u00b0C and cause snowfall. On the contrary, the summer months July-August-September can be hot and rainy, with temperatures exceeding 30\u00b0C. While these external drivers influence the building temperature, vacant and occupied buildings show clear differences, as visible in Figure 2a. </p> <p>In winter, vacant buildings were on average 3 to 4\u00b0C colder than their occupied counterparts, likely due to the absence of heating. In summer, these same buildings often registered higher temperatures, a consequence of the lack of air conditioning or ventilation systems. While occupied buildings range between 28 - 35\u00b0C, vacant buildings are much hotter, with temperatures between 35 and 41\u00b0C .These findings align with expectations, yet the granularity of the data enables a much more precise understanding of building-level dynamics across the urban landscape. </p>          Figure 3: Left: Winter &amp; Summer thermal footprint for buildings in Sapporo with high and low vacancy respectively. Each point represents one building. Right: Winter &amp; Summer thermal footprint for buildings in Sapporo, revealing LST hot- and coldspots."},{"location":"sapporo-use-case/#implications-for-urban-planning-and-policy","title":"Implications for Urban Planning and Policy","text":"<p>High-resolution thermal data offers several advantages for addressing urban vacancy and its associated challenges. First, it enables large-scale, city-wide monitoring of building occupancy without the need for costly field surveys. A single thermal imaging acquisition can cover an area of over 400 square kilometers, providing consistent, repeatable insights across entire metropolitan areas. </p> <p>From a policy perspective, the ability to accurately predict building vacancy allows municipalities to better allocate resources for maintenance, security, and redevelopment. Vacant buildings can be prioritized for reinvestment or adaptive reuse initiatives, potentially revitalizing neighborhoods and stimulating local economies. </p> <p>Thermal data also has significant implications for energy policy and climate resilience. Understanding how vacant and occupied buildings consume and emit energy across seasons supports the design of targeted energy efficiency programs. In regions where energy demand for cooling is projected to double by 2050, such insights are critical for sustainable urban development. </p> <p></p> Figure 4: Final output showing thermal footprints at the building level in 2020, with a trained machine learning model classifying dwelling vacancy. This ready-to-use dataset supports urban-specific case studies and decision-making."},{"location":"sapporo-use-case/#the-broader-context-urban-heat-islands-and-climate-adaptation","title":"The Broader Context: Urban Heat Islands and Climate Adaptation","text":"<p>The relationship between vacancy, land surface temperature, and urban heat islands is increasingly relevant in the context of climate change. As cities experience more frequent and intense heatwaves, understanding how built environments store and release heat becomes essential for public health and climate adaptation planning. </p> <p>Sapporo\u2019s experience is not unique. Cities around the world, from New York to Mumbai are grappling with the challenges of urban vacancy and rising temperatures. High-resolution thermal data provides a scalable, actionable solution for addressing these issues, enabling better planning and more resilient urban environments.</p>"},{"location":"sapporo-use-case/#conclusion","title":"ConclusionDownload demo data","text":"<p>The case of Sapporo demonstrates the potential of thermal intelligence to reshape how we approach urban vacancy and sustainability challenges. By integrating Land Surface Temperature data with population and settlement metrics, constellr offers a new tool for policymakers and urban planners to make data-driven decisions that enhance liveability, energy efficiency, and climate resilience. </p> <p>As constellr\u2019s HiVE constellation continues to expand, offering near-continuous global thermal monitoring, the opportunities for applying thermal intelligence to urban challenges will only grow. Cities seeking to adapt to climate change, optimize resource use, and revitalize underutilized spaces will increasingly rely on data-driven insights like these. </p> <p>The demonstration data provides you with one geojson file of Sapporo's buildings sourced from Open Street Map (OSM): OSM Buildings Vacancy Classification </p> <p>The attribute table contains information on LST for different years per building as well as the final probability of classification as vacant or non-vacant. The README.xlsx file provides information on the different fields of the attribute table: README </p>"},{"location":"thermal-insights/","title":"Thermal Insights","text":"Scientifically sound decision-making across industries <p> Temperature is one of the most critical climate variables, fundamentally governing the water and energy cycle. Across sectors, the impact of rising temperature is profound: in agriculture, it affects crop yields and water availability; in cities, it intensifies urban heat islands and strains public health &amp; energy systems; in infrastructure, it accelerates degradation and failure risk; in defense and intelligence, it alters environmental baselines and operational readiness.</p> Land surface temperature of Freiburg, Germany - June 2023 <p>The scale of the challenge is immense. According to IPCC estimates, the global cost of adapting to a 2\u00b0C warming trajectory could exceed 1.5 trillion E annually by 2030 across sectors. Thermal intelligence \u2014 offering precise, real-time temperature insights \u2014 is essential to reduce these costs. onstellr\u2019s high-accuracy thermal data equips decision-makers with the tools to detect vulnerabilities early, monitor evolving risks, and implement targeted, timely interventions that protect assets, resources and lives across civil and security domains.</p>"},{"location":"thermal-insights/#vegetation-intelligence","title":"Vegetation IntelligenceProducing more with less","text":"<p>Agriculture already uses 70% of all accessible freshwater, but with the global population expected to reach 10 billion by 2050, food production must increase by 60% to feed the world. Agriculture faces immense pressure to produce more with less. By providing real-time, high-resolution temperature data, we enable precision farming like never before. Our insights empower you to optimize water use, boost yields, and ensure your land works harder for you \u2013 sustainably. With constellr's thermal intelligence, you can make every decision count, transforming the way you grow, harvest, and manage resources. constellr\u2019s thermal data provides a holistic picture of soil and plant health, enabling accurate yield predictions, water optimisation and crop profitability.  </p> <p></p> Crop fields in Kansas, USA - June 2022 Crop Stress Monitoring <p>     Healthy vegetation is the foundation of successful farming, and subtle changes in temperature can reveal stress before it\u2019s visible. Plant stress that goes unnoticed can lead to reduced yields, wasted water, and the spread of disease. Agribusinesses, retailers, and farmers use thermal data to detect these shifts early, giving them time to take mitigating action and preserve yields.     </p> <p></p> Soil Temperature Monitoring <p>       Deciding when to plant and how deep to plant into cold soils post winter can be challenging. LST helps agribusinesses, farmers and food chain companies understand the spatial distribution of soil temperature across a field to determine when and how deep to plant, maximizing crop yields from the beginning of the season on.     </p> A bare soil field in Iowa, USA - June 2024 <p></p> Wheat fields in Madhya Pradesh, India - March 2021  Biomass and Yield Monitoring <p>         Canopy temperature analysis is detecting changes in plant transpiration hinting at crop stress. Thermal data can provide this information up to two weeks earlier than current tools, enabling food chain companies, financial institutions and traders to spot crop stress with negative implications for yield before the broader market is aware.     </p>"},{"location":"thermal-insights/#urban-climate-resilience","title":"Urban Climate ResilienceBeat the Heat","text":"<p>Urban environments are increasingly experiencing elevated temperatures due to the Urban Heat Island (UHI) effect, where dense infrastructure absorbs and retains heat. This phenomenon exacerbates health risks with 61% of the world population living in urban environments today. The costs from heat-related stress alone are expected to reach close to a trillion USD annually by 2050 according to a Rockefeller report. Addressing UHIs through urban planning and green infrastructure is essential to mitigate these health risks and economic burdens, causing municipalities to significantly increase their spend on heat mitigation measures. New York City alone expects to spend 55m USD on heat mitigation by 2030. Additionally, UHIs contribute to increased energy consumption due to higher demand for air conditioning, further straining urban infrastructure and escalating costs. constellr's thermal intelligence helps to identify heat-vulnerable areas for targeted intervention and can support the scalable measurement of the effectiveness of mitigation measures. Thanks to its highly accurate thermal measurements capturing even fine contrasts in temperature variation, constellr enables evidence-based urban planning.</p> <p></p> Milano, Italy - December 2024 Urban heat islands <p>     In urban environments, constellr\u2019s ability to detect subtle absolute temperature variations helps to identify urban heat islands, areas where human activity and infrastructure result in higher temperatures. Urban heat islands are becoming a growing concern as cities expand and temperatures rise. Our thermal intelligence helps urban planners and governments to pinpoint temperature hotspots within urban areas, identifying zones with excessive heat. This data supports governments and city planners in developing targeted strategies to reduce heat and improve the liveability of their cities.     </p> <p></p> Heat mitigation measures <p>       Urban vegetation and other heat mitigation measures play a crucial role in reducing heat island effects, improving air quality, and enhancing biodiversity. From trees and parks to green roofs, constellr's thermal intelligence helps urban planners, architects and project developers to track the temperature-reducing effect of mitigation measures on street level, while also enabling monitoring of vegetation health, water usage, and stress levels, enabling better management of urban greenery.     </p> Medellin, Colombia - July 2024"},{"location":"thermal-insights/#infrastructure-intelligence","title":"Infrastructure IntelligenceMinimize Risks","text":"<p>Critical infrastructure\u2014including transport networks, energy systems, and industrial sites\u2014faces increased risks from thermal stress, material degradation, and extreme weather, leading to higher maintenance costs. Currently, global maintenance expenditures for transport infrastructure alone are substantial; for instance, the International Energy Agency (IEA) estimates that combined operations, maintenance, and infrastructure additions in land transport could cost up to a trillion USD by 2050.\u00a0 constellr's thermal intelligence, powered by high-resolution land surface temperature data, offers a proactive solution by identifying vulnerabilities such as heat-induced material fatigue, pipeline leaks, and overheating equipment. Early detection through thermal monitoring reduces damages, prevents costly failures, and optimizes maintenance by targeting high-risk areas, thereby extending asset lifespans and minimizing unscheduled downtime. Integrating thermal intelligence into infrastructure management enhances resilience, lowers maintenance costs, and enables adaptation to the escalating impacts of climate change.</p> <p></p> Colorado, USA - February 2024 Transport infrastructure <p>     Temperature extremes can severely affect road conditions, leading to cracks, ice, and increased wear and tear. Our thermal intelligence helps monitor surface temperatures across road networks, enabling timely interventions for maintenance and repair. Instead of road-level sensors, which are expensive to implement and only offer coverage of specific areas, constellr\u2019s thermal intelligence can monitor large regions simultaneously, ideal for tracking temperature trends across entire cities or highway networks.\u00a0Whether it's detecting freeze-thaw cycles in winter or identifying heat-induced tarmac damage in summer, municipalities and maintenance companies get the insights needed to reduce road deterioration and ensure safer travel, extending the lifespan of the transport infrastructure and reducing costly emergency repairs.     </p> <p></p> Energy infrastructure <p>       From power grids to coal plants, energy infrastructure is vulnerable to the impact of temperature changes. Land Surface Temperature data provides critical insights for monitoring and maintaining energy infrastructure by enabling the detection of thermal anomalies, assessing environmental impacts, and enhancing operational efficiency. This reduces the risk of outages and harm. For power plants, LST helps monitor cooling performance, detect heat leaks, and optimize energy output, especially under rising ambient temperatures. For pipelines, temperature irregularities can be detected, signaling leaks early and thus improving safety and reliability.     </p> Power Plant, Kuwait - November 2023 <p></p> Greenhouse in the Netherlands - April 2024 Industrial Sites Economic Monitoring <p>     By continuously monitoring thermal emissions from industrial sites, we can detect operational inefficiencies, malfunctions and productivity patterns. Our thermal intelligence helps site operators identify and monitor temperature-induced vulnerabilities, offering predictive insights that allow you to act before damage occurs. By tracking temperature shifts that affect structural integrity, we provide a comprehensive view of potential risks\u2014 from material degradation to malfunctioning systems - that allow to prioritize repairs and optimize maintenance schedules. Additionally, financial institutions use constellr's thermal intelligence for monitoring the activity of industrial sites to derive productivity information.     </p>"},{"location":"thermal-insights/#defense-intelligence","title":"Defense &amp; IntelligenceSecure national interests","text":"<p>Protecting national interests in an increasingly unstable world requires timely, persistent, and multi-dimensional situational awareness. Defense and intelligence agencies face mounting challenges \u2014 from monitoring hostile activity and infrastructure vulnerabilities to tracking illicit operations such as dark vessel movements and cross-border incursions. Existing Earth observation tools, while powerful, leave critical blind spots in low-light or camouflaged conditions. This is where thermal data becomes indispensable. By capturing the surface-emitted heat, thermal intelligence reveals what\u2019s otherwise invisible: human presence, equipment activity, energy use, and environmental change \u2014 day or night. The strategic value is immense: thermal sensing enhances surveillance, accelerates threat detection, and supports mission planning at both strategic and tactical levels. As global tensions rise and the demand for sovereign, high-resolution intelligence grows, thermal data is no longer optional \u2014 it's foundational.  </p> Maritime Security: Vessel Detection <p>   Monitoring vessel activity in open waters is becoming increasingly challenging, as more vessels operate without AIS transponders, identification systems, or operate at night to evade radar and optical surveillance. These so-called \u201cdark vessels\u201d pose risks ranging from illegal fishing and smuggling to human trafficking and unauthorized military activity. Constellr\u2019s thermal data detects vessel heat signatures day and night, regardless of light conditions or camouflage, and can even pick up small non-metal vessels often missed by radar, for which radar returns ambiguous signals.. Thermal wakes reveal movement direction, enabling agencies to detect, track, and respond more effectively \u2014 strengthening border protection, maritime security, and international collaboration.     </p> Dakar, Senegal - June 2025 <p></p> Nile Delta, Egypt - July 2025 Situational Awareness: Terrain Analysis <p>     In dynamic security and defense environments, terrain plays a critical role in operational planning and threat assessment. Traditional optical and radar imagery can map elevation and surface features but often miss subtle environmental cues - such as recent activity, movement, or heat-related anomalies - especially under low-light or obscured conditions. This creates blind spots in situational awareness, particularly in conflict zones, border regions, and remote areas. Thermal data fills this gap by revealing heat signatures across terrain, highlighting soil disturbances, like the creation of trench structures, buried supply lines or other concealed structures. constellr\u2019s thermal intelligence enables detection of heat differentials in ground surfaces, allowing operators to identify paths of movement, and terrain changes \u2014 even at night or through partial cover. This adds a critical, persistent layer of insight for real-time decision-making in complex operational environments.     </p>"},{"location":"water-stress-use-case/","title":"Water stress use case","text":"Detecting water stress using spaceborne LST  <p>Download the graphcial abstract here. </p>"},{"location":"water-stress-use-case/#crop-stress-monitoring","title":"Crop Stress MonitoringDownload demo data","text":"Figure 1: A corn field after canopy closure  (photo credit Charlie Siggs) <p>     In the vast fields of corn across the United States, growing successful crops depends on detecting problems early (Figure 1). In such fields, water stress is one of the most common challenges, but it is not always easy for the land manager to spot. A section of the field might start to struggle, but by the time the signs are visible, it might already be too late to fully recover. Fortunately, constellr\u2019s spaceborne technology is changing how farmers can manage their fields. Satellites equipped to measure land surface temperature detect subtle heat changes caused by water stress, often long before it is noticeable from the ground. This story demonstrates the detection of water stress using in-house derivation of LST from thermal acquisitions of Landsat 8 and Landsat 9 and a story of satellite data capturing the faint heat signals of stress before the harvest suffers.      </p> <p>In many parts of the United States, corn fields are circular, shaped by the sweeping arms of center-pivot irrigation systems. These systems rotate around a central point, delivering water evenly across the field to support the crop's growth. From above, these circular fields look like giant green disks against the earth\u2019s surface (Figure 2). Satellites capture this unique geometry while also providing detailed information about the field's condition.  </p> Figure 2: Circular corn fields as viewed from the ground and from space  <p></p> <p>     The corn begins as tiny green shoots, gradually growing into tall plants with broad leaves that form a thick, protective canopy. Over time, tassels appear at the top, signaling pollination, and soon after, the corn cobs develop, hidden in their husks until harvest. Using vegetation indices like NDVI (Normalize Difference Vegetation Index) from space, one can follow the field\u2019s greening and growth stages. NDVI provides an indication of where there may be issues. Yet, when there is a large amount of vegetation, NDVI tends to saturate. Corn with comparable NDVI values could actually be in very different states.\u202f This would be comparable to someone looking for a new house, by only looking at the price. For the same price, you can rent a small apartment in a city center, or a larger house in the countryside. The price alone is thus a poor proxy for localisation and size.      </p> Figure 3: NDVI time-series of a corn field  in Kansas, USA <p>On the other hand, it is essential to understand the importance of temperature and water at different growth stages (Figure 4). During healthy growth, the corn canopy cools the surface by shading the soil and releasing moisture through transpiration. At critical times, such as crop establishment or pollination, further information, such as field level meteorological or field-sensor data are needed to understand the crop status.\u202f This data can be provided through in-field weather stations and soil sensors, but these are limited by cost and area of coverage. </p> <p></p> Figure 4: The different growth stages of corn and the phases where temperature and water are critical  <p> Considering one field that has a sector that is not well irrigated in the red triangle shown in Figure 5, we can detect this stress using thermal data before you can catch it with a vegetation index such as NDVI. </p> <p></p>  Figure 5: Timeline of a corn field after canopy closure with a segment that is not well irrigated (bounded by the red triangle)  <p></p>  Figure 6: LST maps of the field showing the temperature variation with the segment of the fields that is not well irrigated shown in the red triangle  <p>By using just a few thermal images of LST data, acquired during the early vegetation growth stage of corn (from June 11 to June 28), LST can already identify a substantial portion of pixels deemed abnormal throughout the entire vegetation growth period (indicated by the red triangle, Figure 6). On the other hand, NDVI needed additional images (from June 11 to July 22) to flag a significant number of pixels as abnormal. Using machine learning techniques, such as One-Class Support Vector Machine (OC-SVM), patterns can be identified in an automated manner where anomalies that deviate significantly from the norm within a corn field can be detected.  </p> <p>This implies:</p> <ul> <li>Land Surface Temperature (LST) provides valuable insights into biophysical parameters, moving us from proxies to direct measurements. </li> <li>While NDVI reveals how the crop looks on the surface, it does not explain what is happening beneath or why it looks that way. </li> <li>By combining LST with indices like NDVI, we gain a more holistic view of the crop canopy. </li> </ul> <p>For example, when parts of a field experience water stress, the plant stomata close, causing those areas to warm up, and thus subtle heat signatures that can be observed from space. By analyzing these satellite observations at each stage of a crop\u2019s life cycle, such as corn, we can detect stress early and help farmers take action to maximize their yields.  </p>    With high-resolution LST data, we can identify these issues early and precisely. In 2025, even more powerful datasets will be available. We look forward to quantifying the major improvements of the outcome with LST fusion to monitor large areas of corm, LST precision to obtain the highest accuracy and sensitivity, as well as LST zoom for the greatest details.  <p>Special thanks to Charlie Siggs, Nicolas Chamberland, Loic Quertenmont, Elsy Ibrahim, Rosa Schmidt, Yan de Paoli, and Lena Rester for their valuable contributions to this study and its documentation. Their insights, dedication, and support played a key role in shaping this work.  </p> <p></p> <p>The demonstration data provides you with csv files containing a timeseries of the growing season of one corn field. It includes the median and standard deviation of 1) in-house derivation of LST data from thermal acquisitions of Landsat 8 and Landsat 9 data for the water-stressed field section, 2) in-house derivation of LST data from thermal acquisitions of Landsat 8 and Landsat 9 for the well-watered field section. Additionally, the NDVI mean and quantiles for the whole field are provided which have been sourced from Landsat 8 data. </p> <p>LST timeseries for a stressed section of the field </p> <p>LST timeseries for the irrigated part of the field </p> <p>NDVI median of the field</p>"}]}